{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e54c27",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d3a087fc5508193fe5757d043fe26f1",
     "grade": false,
     "grade_id": "cell-dff56f438a8537a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Worksheet 07: Predictive versus generative modelling\n",
    "\n",
    "\n",
    "### Learning objectives\n",
    "By the end of this section, students will be able to:\n",
    "\n",
    "- Give examples of questions that can be answered by generative models and others that can be answered by predictive models.\n",
    "- Discuss how the research question being asked impacts the statistical modelling procedures.\n",
    "- Discuss why the model obtained directly from lasso is not the most suitable model for generative modelling and how post-lasso is one way to address this problem.\n",
    "- Write a computer script to perform post-lasso and use it to estimate a generative model.\n",
    "- Discuss post inference problems (e.g., double dipping into the data set) and current practical solutions available to address these (e.g., data-splitting techniques).\n",
    "- Write a computer script to apply currently available practical solutions to post inference problems.\n",
    "- Discuss how the research question being asked impacts the communication of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add787fc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94eda6d83569c6eb9836f9280ad7dcb9",
     "grade": false,
     "grade_id": "cell-42bb9496684954db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(glmnet)\n",
    "library(broom)\n",
    "library(leaps)\n",
    "library(repr)\n",
    "library(faraway)\n",
    "library(mltools)\n",
    "\n",
    "options(repr.plot.width=10, repr.plot.height=8)\n",
    "source(\"tests_worksheet_07.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e6a50",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d31d978cb06fb6180c15e0db8618862a",
     "grade": false,
     "grade_id": "cell-b6a517078dce99d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# PART I: Model selection (cont.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848ffe4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f25704415f6b03269fb126446df7918f",
     "grade": false,
     "grade_id": "cell-6f048d81f2cffe21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## In worksheet_06: \n",
    "\n",
    "### Select a model using *stepwise* algorithms\n",
    "\n",
    "- these are *greedy* algorithms \n",
    "\n",
    "- results depend on the order in which variables are selected \n",
    "\n",
    "- variables are either *in* (i.e., estimated coefficient different from zero) or *out* (i.e., estimated coefficient equal to zero)\n",
    "\n",
    "## In this worksheet:\n",
    "\n",
    "- can we use the selected model to make inference about the population?\n",
    "\n",
    "- can we use shrinkage methods to select a model and make inference?\n",
    "\n",
    "Let's examine these problems using a simulation study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40216a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4dcafb35fea019a1ac2394a5f69c81a",
     "grade": false,
     "grade_id": "cell-4db8971f16f54c5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## PART I: Inference after model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6d03e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "de59600c1f1e6c02486eadc6318ce03b",
     "grade": false,
     "grade_id": "cell-52b0432e6c14a90f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. Can we make inference using the selected models??\n",
    "\n",
    "In this course, we learned how to make inference (e.g, calculate confidence interval and hypotheses tests) for a fixed model. However, when we apply a model selection algorithm, we are searching for the combination of variables that will give us the best model (according to a given metric). So the variables in our final models are not fixed; instead, they are selected adaptively based on **the data at hand**. \n",
    "\n",
    "Two questions arise then: \n",
    "\n",
    "1. Do these model selection algorithms affect the inference about the parameters of the model? \n",
    "\n",
    "2. Is the way we interpret the models still the same? \n",
    "\n",
    "Now we will investigate the first question. For now, let's focus on the forward selection. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a3b93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89fd242b3b9e07e5b055f375e2b4bd56",
     "grade": false,
     "grade_id": "cell-aa995988a3e3146f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.0**<br>\n",
    "\n",
    "In this exercise, we will explore if the forward selection strategy affects the inference results. For this purpose, we are going to use a simulation study in order to know the truth. Here's what we are going to do: \n",
    "\n",
    "1. We are going to consider a response variable $Y$ and $p=10$ independent variables. However, none of the generated variables will have an effect on $Y$. In other words, in this simulation study, we expect the intercept only model to be better than any LR that includes any of the independent variables.\n",
    "\n",
    "\n",
    "2. Generate 100 observations of each variable (the response and the 10 independent variables) from a Normal distribution.\n",
    "\n",
    "\n",
    "3. Apply the forward selection algorithm to select at most 3 variables among the 10 available. We restrict the size to 3 to shorten the computation time.\n",
    "    - The metric we are going to use is the adjusted $R^2$.\n",
    "\n",
    "4. Use the selected model to make inference about the population. Recall that none of the independent variables is related to the response Y. However, due to randomness in the sample used, we may still (incorrectly) find a model that it's statistically better than the intercept only model! \n",
    "\n",
    "5. Replicate this study 1,000 times and compute the type I error rate. \n",
    "\n",
    "> Note that we are generating 1,000 datasets, all at once!! We will use the `map` function to apply a function to each dataset.\n",
    "\n",
    "*Run the cells below to generate the datasets.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72d705",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5dc0b2f3ce9215e4568223312d733f1",
     "grade": false,
     "grade_id": "cell-8196a2c8170de40f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing \n",
    "set.seed(20211113)\n",
    "\n",
    "n <- 100    # sample size\n",
    "p <- 10     # number of variables\n",
    "rep <- 1000 # number of replications\n",
    "\n",
    "means <- runif((p+1), 3, 10) # means for the Normal distribution \n",
    "                             # that will be used to generate \n",
    "                             # p covariates and a response Y   \n",
    "\n",
    "dataset <- as_tibble(\n",
    "  data.frame(\n",
    "    matrix(\n",
    "      round(rnorm((p + 1) * n * rep, \n",
    "            means, 10), 2), \n",
    "      ncol = p+1, \n",
    "      byrow = TRUE\n",
    "    )\n",
    "  ) %>% \n",
    "  rename(Y = X11) %>% \n",
    "  mutate(replicate = rep(1:rep, n)) %>% \n",
    "  arrange(replicate) \n",
    ")\n",
    "\n",
    "head(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd8d4d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1021b33f47f86cd6de08427ecf0cd7b5",
     "grade": false,
     "grade_id": "cell-99c152c3ff4d28bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc40c0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5fd64c8c481d87f888bf440b82735c90",
     "grade": false,
     "grade_id": "cell-038f4a539d529c3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1 - Warm up**<br>\n",
    "{points: 1}\n",
    "\n",
    "To help you visualize the code abstraction, let's do a more intuitive exercise. \n",
    "Using the `dataset` tibble, fit one `lm` for each replicate using all 10 covariates to explain $Y$. Store the `lm` models in a column named `models`.\n",
    "\n",
    "_Assign your data frame to an object called `full_models`. Your data frame should have three columns: `replicate`, `data`, and `models`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534afbfd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86766ab99f82c294f0ccf2092e6a80cc",
     "grade": false,
     "grade_id": "cell-d5570a80d2c30190",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full_models <- \n",
    "#     ... %>% \n",
    "#     group_by(...) %>% \n",
    "#     nest() %>% \n",
    "#     mutate(models = map(...))\n",
    "\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "# Try exploring the columns of your data frame. \n",
    "# Check full_models$data[[1]] and full_models$models[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d43162",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32c0e51490fab08ed3f8b4769094907c",
     "grade": false,
     "grade_id": "cell-3e2a31ce11918efb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_models$models[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e65c4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cddd6f329ec006cd25a59dbb4b7e71d7",
     "grade": true,
     "grade_id": "cell-a4f7c92013fb0e66",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd12db00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff34c50145946f94357b172504c9eb53",
     "grade": false,
     "grade_id": "cell-7f2f7877c77c43b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To help speed things up, we created a function for you that receives a data frame, runs the forward selection algorithm to select at most 3 variables, and fit LS on the selected variables. \n",
    "\n",
    "*Read and run the cell below to create such a function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369059b-8954-4b1e-a8a5-23280f4e0b58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db221033548638060c55d29167b7e2d2",
     "grade": false,
     "grade_id": "cell-45cd02979d22326a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "forward_selection_function <- function(dataset){\n",
    "    sel_model <- regsubsets(x = Y ~ ., \n",
    "                    nvmax = 3,\n",
    "                    data = dataset,\n",
    "                    method = \"forward\",\n",
    ")\n",
    "\n",
    "sel_model_summary <- summary(sel_model)\n",
    "    \n",
    "adj_r2_min = which.max(sel_model_summary$adjr2) \n",
    "selected_var <- names(coef(sel_model, adj_r2_min))[-1]\n",
    "data_subset <- dataset %>% select(all_of(selected_var),Y)\n",
    "\n",
    "selected_model <- lm(Y ~ .,\n",
    "  data = data_subset\n",
    ")\n",
    "    return(selected_model)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82f1ef-0dc7-494d-a25f-2ce5a7e5d8e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "955f4dd2b0bed9dd5bc85f54146589f1",
     "grade": false,
     "grade_id": "cell-50027fa08dcbf86b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Question 1.2**<br>\n",
    "{points: 1}\n",
    "\n",
    "The function `forward_selection_function` will be used to select and fit a model on a given data set using LS. We will then compare the selected model to the intercept only model using an $F$-test. Which null hypothesis will be tested:\n",
    "\n",
    "**A**. The coefficient of the first variable selected equals zero.\n",
    "\n",
    "**B**. The coefficient(s) of all selected variables equal zero.\n",
    "\n",
    "**C**. The selected variables equal zero.\n",
    "\n",
    "**D**. The intercept equals zero.\n",
    "\n",
    "*Assign your answer to an object called answer1.2. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"`, surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0901396-60f7-486c-bba6-beeafa2c42e8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a6c67d96292014ec80274f05805d5c6",
     "grade": false,
     "grade_id": "cell-03b617e11f90e205",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer1.2 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d163bc-fc05-4e6d-b011-83a71131e339",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d9cdc2c6d9550692b3b8cdbd831941f",
     "grade": true,
     "grade_id": "cell-725cbb37dbd83df9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8eee59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e3506ee9260a4858c53d810dd151190d",
     "grade": false,
     "grade_id": "cell-e2ca8b6be7d1c675",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.3**<br>\n",
    "{points: 1}\n",
    "\n",
    "Using the function `map`, apply the `forward_selection_function` to each generated dataset in the tibble `dataset`, identified by the variable `replicate`. Store each fitted model in a column named `fs_model`. \n",
    "\n",
    "> Note that there are 1000 fitted models, one for each dataset generated in **Question 1.0**!! \n",
    "\n",
    "Then, use the function `map_dbl` to compare each selected model to the intercept only model and extract the $p$-value of each $F$-test. Store the 1000 $p$-values in a column named `F_pvalue`.\n",
    "\n",
    "_Assign your data frame to an object called `forward_selection_F`. Your data frame should have four columns: `replicate`, `data`, `fs_model`, and `F_pvalue`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a70bba",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fef74d7079570af1852559e7421529a2",
     "grade": false,
     "grade_id": "cell-bf37cd17c298bbb8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# forward_selection_F <- \n",
    "#     ... %>% \n",
    "#     group_by(...) %>% \n",
    "#     nest() %>% \n",
    "#     mutate(\n",
    "#         ... = map(...), \n",
    "#         ... = ..._dbl(...)\n",
    "#     )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(as.data.frame(forward_selection_F), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e605b8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "607abf979af80f62ac2c1c6953a5d433",
     "grade": true,
     "grade_id": "cell-eabe9532c5e44b6d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec61e4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "549bbd8ad6296f34ea6debb8f14e943f",
     "grade": false,
     "grade_id": "cell-c4f15d48f178784a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.4** \n",
    "<br> {points: 1}\n",
    "\n",
    "Knowing that none of generated independent variables are relevant to model $Y$, what proportion of tests would you expect to wrongly reject the null hypothesis that the coefficients of all the selected variables are zero? Consider the significance level of 5%.\n",
    "\n",
    "_Assign your answer to an object called `nominal_type_I_error`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259555f8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "295db2ccd2742ff13fb194a4fe1be60d",
     "grade": false,
     "grade_id": "cell-beba772a72681900",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nominal_type_I_error <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "nominal_type_I_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013daa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a7ea6e3978da8cd7623b00c41450b82",
     "grade": true,
     "grade_id": "cell-8d98c976a828e040",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc7c7e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6516d2d4ab1c55c28bc23d26e4f1a2c4",
     "grade": false,
     "grade_id": "cell-ccc6a385e1043ed0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.5** \n",
    "<br> {points: 1}\n",
    "\n",
    "Check the proportions of $p$-values computed from the $F$-tests stored in the `forward_selection_F` tibble that are below the 5% significance level. \n",
    "\n",
    "_Assign your answer to an object called `forward_selection_type_I_error`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a08f82-a78b-45fe-89a6-46c2bfe33b90",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4923a0444dd528dc82b7d7bb43f56fca",
     "grade": false,
     "grade_id": "cell-2fa4716ac32bbaf7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# forward_selection_type_I_error <- \n",
    "#     ... %>% \n",
    "#     ungroup() %>% \n",
    "#     summarise(...(... < 0.05)) %>% \n",
    "#     pull()\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "forward_selection_type_I_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6bf221",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fe2356dd35968af3b88d00666d4bed1",
     "grade": true,
     "grade_id": "cell-6c32bbee9d728156",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.5()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda2121a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e862e91d5bed6ccf90ce0362edd1d5a",
     "grade": false,
     "grade_id": "cell-fb759982412336e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Class discussion \n",
    "Contrast the `forward_selection_type_I_error` and `nominal_type_I_error`. Are they similar? Why do you think this is happening. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ad366c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c5b24627d835da014f4b2f680192529",
     "grade": false,
     "grade_id": "cell-d34cab1fa0787324",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. The double use of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775dd9f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac6a407688a2d911c26ce396a9b95398",
     "grade": false,
     "grade_id": "cell-e7302f3b294124f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The Type I Error rate from the tests run using the fitted selected models was significantly higher than the nominal level of 5%. Why? \n",
    "\n",
    "Well, if we are looking for the most relevant covariates in a dataset, it is not surprising that we frequently find these covariates significant. In our case above, the *F-statistic* compares the reduction of SSR after adding the selected variables to an intercept-only model. But the variables selected were those that reduced the SSR (or increased the adjusted $R^2$) **in the sample at hand**. Hence, we have a much higher chance of wrongly rejecting $H_0$.  \n",
    "\n",
    "**The problem**: we are using the **same sample** to find the variables and fit the model. \n",
    "\n",
    "**A possible solution**: what if we split the dataset into two parts, one used for model selection and the other one used for inference? Would that solve the problem? \n",
    "\n",
    "Let's investigate! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043329f5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cf6b6dcfedc41c156e5372528c5eb9a",
     "grade": false,
     "grade_id": "cell-1a771305759350ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.0** \n",
    "<br> {points: 1}\n",
    "\n",
    "In this exercise we are again going to use the tibble `dataset`. But this time we are going to split our dataset into two parts. We are going to use one part to select a model, and the other part for inference. Since the sample sizes has changed, to compare strategies, we'll also fit the selected model and test it on the first set.\n",
    "\n",
    "> For this exercise, let's split the dataset in half. Note that other options are possible.\n",
    "\n",
    "Here's what you need to do: \n",
    "\n",
    "1. Using the first 50 observations, run the forward selection algorithm to select at most 3 variables and fit a LS on the selected variables. Store the selected model in `fs_model` column. \n",
    "\n",
    "\n",
    "2. Run an $F$-test to compare the selected model to an intercept only model and extract the $p$-value. Store the 1000 values in a column called `F_fs`.\n",
    "\n",
    "\n",
    "3. Fit the model selected in Step 1 using the 50 remaining observations and save it in a column named `inference_model`. Also, extracts the $p$-value of the $F$-test for the `inference_model` and stores it in a column called `F_pvalue`. \n",
    "\n",
    "> Note that using the `map` functions you can perform these steps at once for the 1000 datasets.\n",
    "\n",
    "_Assign your data frame to an object called `fs_error_split`. Your data frame should have 6 columns: `replicate`, `data`, `fs_model`, `F_fs`, `inference_model`, `F_pvalue`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e70736",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d6c3be6ad8b2ce867091adc4e38caca",
     "grade": false,
     "grade_id": "cell-b544356ca3740453",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(20211113) # Do not change this.\n",
    "\n",
    "# fs_error_split <- \n",
    "#     ... %>% \n",
    "#     ... %>% \n",
    "#     ... %>% \n",
    "#     mutate(\n",
    "#         fs_model = ...(..., .f = function(d) forward_selection_function(d %>% head(50))), \n",
    "#         F_fs = ...,\n",
    "#         inference_model = map2(.x = ..., .y = ..., ~ update(.y, .~., data = .x %>% tail(50))), \n",
    "#         F_pvalue =  ...)\n",
    "#     )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "        \n",
    "head(fs_error_split) %>% \n",
    "    select(replicate, F_fs, F_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e35bbe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea2c4f4d0994cd127fca18eab3d97fcf",
     "grade": true,
     "grade_id": "cell-87cd37c4793c4935",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e07955-9ffa-4112-afcd-43558926ae6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1b7989084ce70eb06f0eeca12c6851d",
     "grade": false,
     "grade_id": "cell-85ee6bf7f4767ba4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Question 2.1** \n",
    "<br> {points: 1}\n",
    "\n",
    "Check the proportions of $p$-value of the $F$-test in the `F_fs` column that are below the 5% significance level. Note that these tests were run using the the first split of the data used to select the model.\n",
    "\n",
    "> Hint: you've done something similar in **Question 1.5**\n",
    "\n",
    "_Assign your answer to an object called `fs_split1_type_I_error`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ac98d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bf1783034bbbeb51bf3f4473b40ed79",
     "grade": false,
     "grade_id": "cell-d63bd5b3efb2ae77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fs_split1_type_I_error <- ... \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "fs_split1_type_I_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c72122-3478-4fe4-b92e-a9e79bc22080",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fb18c80bd66003cf0fa201148a4e74f",
     "grade": true,
     "grade_id": "cell-1c5a6ffc1c5a7870",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce156766",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "163349416093b6fa45f78fd36714b5ba",
     "grade": false,
     "grade_id": "cell-d98b56dbc789635d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.2** \n",
    "<br> {points: 1}\n",
    "\n",
    "Check the proportions of $p$-value of the $F$-test in the `F_pvalue` column that are below the 5% significance level. Note that these tests were run using the the second split of the data that was *not used* to select the model.\n",
    "\n",
    "\n",
    "_Assign your answer to an object called `fs_split2_type_I_error`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d377e-0e60-4396-9be8-9a7f6cd33635",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "592b4065cc1e2d751e6777f22506753d",
     "grade": false,
     "grade_id": "cell-d647eb0fcdf010b7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fs_split2_type_I_error <- ... \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "fs_split2_type_I_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d7e65d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cafcfe80dc79b11c6b44debae63a81b0",
     "grade": true,
     "grade_id": "cell-9b2666ff7cd4089f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e615d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ea6d67b3cd0c8daa8ccfe0726ce144c",
     "grade": false,
     "grade_id": "cell-851de6eae8846cad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "If we split the data and use different part for model selection and inference, the type I error of the F-test after the forward selection is close to the significance level. \n",
    "\n",
    "_Assign your answer to an object called `answer2.3`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316403a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3cb008e24b17c8eeb2b1fca6b93b15cf",
     "grade": false,
     "grade_id": "cell-f1a4e23880603605",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer2.3 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4f30c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9101658c51073046a250b7d9e555b55d",
     "grade": true,
     "grade_id": "cell-b588d3c3d475102a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69469f9e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "132d869760d55990cd3545b166c9a9ea",
     "grade": false,
     "grade_id": "cell-219ec4f75a9ad8f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## PART II. Lasso - two problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145e2dd4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4bc168ab8f82e47558880698e47119d2",
     "grade": false,
     "grade_id": "cell-05afee85a589325b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The problem we discussed with the forward selection *also happens with Lasso*. Similarly, we can address it by splitting the dataset -- one part for selecting variables using lasso and the other for fitting the model for inference. \n",
    "\n",
    "However, there's another problem with Lasso for inference. Lasso's estimators are biased. Bias estimators are estimators whose sampling distributions are not centred on the true value of the parameter. \n",
    "\n",
    "To study this problem, we are going to use a new simulation, Our population is generated below and it is stored in `lasso_sim` tibble.\n",
    "\n",
    "The population was generated such that:\n",
    "\n",
    "$$\n",
    "E[Y|X_1, X_2] = 75X_1 - 5 X_2 + 0 X_3\n",
    "$$ \n",
    "\n",
    "Therefore, the true parameters are $\\beta_1=75$ and $\\beta_2=-5$. Note that $\\beta_3$ is not a relevant variable and, hopefully, Lasso will remove it from the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8fa6c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6e5a079e9636b0aa248c6f98b4692ee",
     "grade": false,
     "grade_id": "cell-95df2b5999161495",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing \n",
    "\n",
    "set.seed(20211113) # Do not change this.\n",
    "\n",
    "n <- 1000    # sample size\n",
    "rep <- 1000 # number of replications\n",
    "\n",
    "lasso_sim <- \n",
    "    tibble(\n",
    "        X1 = round(\n",
    "                rnorm(n * rep, 0, 10), \n",
    "                2),\n",
    "        X2 = round(\n",
    "                rnorm(n * rep, 0, 10), \n",
    "                2),\n",
    "        X3 = round(\n",
    "                rnorm(n * rep, 0, 20), \n",
    "                2),\n",
    "        Y = round(75 * X1 - 5*X2 + rnorm(n * rep, 0, 400),2)) %>% \n",
    "    mutate(replicate = rep(1:rep, n)) %>% \n",
    "    arrange(replicate) \n",
    "\n",
    "\n",
    "head(lasso_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90e4ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47ef6e9a3f4bd4c2ecdf0355c988a14c",
     "grade": false,
     "grade_id": "cell-4665f4f34800f47c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.0**<br>\n",
    "{points: 1}\n",
    "\n",
    "Using the `lasso_sim` tibble, fit a LASSO model for each replicate. For simplicity, we'll use $\\lambda=30$ in all models. \n",
    "\n",
    "> However, in practice, it is not recommended to fit LASSO at a given lambda value. \n",
    "\n",
    "Store the models in a column named `lasso_models`. \n",
    "\n",
    "_Assign your data frame to an object called `lasso_study`. Your data frame should have four columns: `replicate`, `data`, and `lasso_model`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18767685",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7ff031f66814fb970e23e3fd2239164",
     "grade": false,
     "grade_id": "cell-aa46e5df61e9558b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lasso_study <- \n",
    "#     ... %>% \n",
    "#     ... %>% \n",
    "#     ... %>% \n",
    "#     mutate(\n",
    "#         lasso_model = ...(...,\n",
    "#                           ~...(.x %>% select(-Y) %>% as.matrix(), \n",
    "#                                   .x %>% select(Y) %>% as.matrix(), \n",
    "#                                   alpha = ..., \n",
    "#                                   lambda = ...)))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(as.data.frame(lasso_study), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86648684",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa634d02f59e6adcaff634edf9519465",
     "grade": true,
     "grade_id": "cell-d68d670ab6c2496c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f7f81",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41e02801dd2fed8035c2732886ee6011",
     "grade": false,
     "grade_id": "cell-2a61e4f25256cc82",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.1**<br>\n",
    "{points: 1}\n",
    "\n",
    "Extract the coefficient for `beta_1` from each `lasso_model` in the `lasso_study` tibble. Store the coefficients in a column name `lasso_beta1` in the same `lasso_study` tibble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a3cfd4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31898d3a60f9cc3d0c9c96ccc3c6060e",
     "grade": false,
     "grade_id": "cell-eb3b9bba09b060d0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lasso_study <- \n",
    "#     ... %>% \n",
    "#     ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(as.data.frame(lasso_study %>% select(-data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26531f67",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d06437da0829fb80a9553d775680a3d",
     "grade": true,
     "grade_id": "cell-8ebd4cdf24d174b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef540c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9529fa8602f597c4fea97b11b2fe82ae",
     "grade": false,
     "grade_id": "cell-3472a426b731a695",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2**\n",
    "<br> {points: 1}\n",
    "\n",
    "Plot the sampling distribution of $\\hat{\\beta}_1$ obtained by Lasso.\n",
    "\n",
    "\n",
    "_Assign your plot to an object called `lasso_beta1_sampling_dist`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac61836",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5779b29e5d3766e625ebfffe7c02f9ca",
     "grade": false,
     "grade_id": "cell-21508cb2d3c1b17b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lasso_beta1_sampling_dist <- \n",
    "#     lasso_study %>% \n",
    "#     ggplot() + \n",
    "#     geom_...(aes(...), color='white') +\n",
    "#     geom_vline(xintercept = 75, color = 'red') + \n",
    "#     geom_text(aes(75, 110), label = \"True Value of the Parameter\", color = 'red') \n",
    "#     geom_text(aes(75, 80), label = \"True Value of\\n the Parameter\", color = 'red', size = 7) +\n",
    "#     theme(text = element_text(size = 18))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "lasso_beta1_sampling_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a92fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3f65a8051c55e25a3306621fe64b20dd",
     "grade": true,
     "grade_id": "cell-3b289632e05ad195",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90bc4e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46c0f0301181cf79c727536d8e68601b",
     "grade": false,
     "grade_id": "cell-ae58776784170e6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "The sampling distribution of the lasso estimator of $\\beta_1$ is centered around the true $\\beta_1$.\n",
    "\n",
    "_Assign your answer to an object called `answer3.3`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707ad82",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "202680a0eb4c6878694ba880378bdfa6",
     "grade": false,
     "grade_id": "cell-cbc53e1b3025df42",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer3.3 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30fe597",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cb7ba32a9741e7f47696b920205fe4e",
     "grade": true,
     "grade_id": "cell-2c1d0b19fb80ea91",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf344ca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "720b78f657ea1dc77ad1778f52ec1227",
     "grade": false,
     "grade_id": "cell-70b6424c44d2cb6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.4**<br>\n",
    "{points: 1}\n",
    "\n",
    "One way to correct the bias of the Lasso's estimated coefficients is to re-fit the model using LS and the variables selected by LASSO. In other words, we use LASSO only to select variables and ignore the estimated coefficients. We then re-estimate the coefficients of the selected variables using regular least squares. \n",
    "\n",
    "In the cell below we have done it for you. Here's what we did:\n",
    "\n",
    "1. Add a new column to `lasso_study` tibble, named `lasso_selected_covariates` with the covariates selected by LASSO (i.e., with coefficients different from 0).\n",
    "\n",
    "\n",
    "2. We fitted a linear model using `lm` (regular least square) and only the `lasso_selected_covariates`.\n",
    "\n",
    "\n",
    "3. We extracted $\\beta_1$ from the `lm` model, and saved it on a column called `ls_beta1`.\n",
    "\n",
    "Your job is to plot the sampling distribution of $\\hat{\\beta}_1$ obtained by the regular least square, using the variables selected by LASSO.\n",
    "\n",
    "_Assign your plot to an object called `post_lasso_lm_beta1_sampling_dist`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2e8a34",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e7151c2d9aeb829a0c8eff35b7338b7",
     "grade": false,
     "grade_id": "cell-6920e00dbec79884",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing\n",
    "\n",
    "lasso_study <- \n",
    "    lasso_study %>% \n",
    "    mutate(\n",
    "        lasso_selected_covariates = map(.x = lasso_model, \n",
    "                                        ~as_tibble(\n",
    "                                                as.matrix(coef(.x)),\n",
    "                                                rownames='covariate') %>%\n",
    "                                                filter(covariate != '(Intercept)' & abs(s0) > 10e-6) %>% \n",
    "                                                pull(covariate)),\n",
    "        ls_fit = map2(.x = data, .y = lasso_selected_covariates,\n",
    "                     ~lm(Y ~ ., data = .x[,c(.y, 'Y')])),\n",
    "        ls_beta1 = map_dbl(.x = ls_fit, ~tidy(.x) %>% filter(term == 'X1') %>% pull(estimate)))\n",
    "\n",
    "\n",
    "lasso_study %>% \n",
    "    select(-data, -lasso_model, -ls_fit) %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1707c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2db9c9581d5024293846a809b4343987",
     "grade": false,
     "grade_id": "cell-dd0e4b4d53066426",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# post_lasso_lm_beta1_sampling_dist <- \n",
    "#     lasso_study %>% \n",
    "#     ggplot() + \n",
    "#     geom_...(aes(...), color='white') +\n",
    "#     geom_vline(xintercept = 75, color = 'red') + \n",
    "#     geom_text(aes(75, 80), label = \"True Value of\\n the Parameter\", color = 'red', size = 7) +\n",
    "#     theme(text = element_text(size = 18))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "post_lasso_lm_beta1_sampling_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b095d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8233a8cf25cbdede0a4ad162456b4fe",
     "grade": true,
     "grade_id": "cell-69a5a5d6f0125c49",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c7c05b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e523ed80654ad28f2c5923aa74bd910",
     "grade": false,
     "grade_id": "cell-47eca90d66532852",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "#### Post-inference problem:\n",
    "\n",
    "- we can not use the same data to select variables of the model and to conduct inference (\"doble dipping\"). \n",
    "\n",
    "- the inference results given by the `lm` are not valid (as seen in the first part of the worksheet). \n",
    "\n",
    "- if we split the data, we can use one part to select and the other part to estimate and build tests.\n",
    "\n",
    "- more sophisticated methods have been proposed to address this problem (beyond the scope of this course).\n",
    "\n",
    "\n",
    "#### Lasso has two problems:\n",
    "\n",
    "- **Biased estimators**: we can take care of this by fitting regular least squares on the variables selected by Lasso. This approach is called **post-lasso**.\n",
    "\n",
    "- **Post-inference**: fitting a LS regression after LASSO, we are using the data to select the variables as well as to conduct inference. We cannot rely on the inference given by the `lm`, unless we split the data to take care of this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
