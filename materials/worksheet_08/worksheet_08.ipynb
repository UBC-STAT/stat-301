{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e54c27",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13e6a747cc65ed51614ad07f6ead6a5d",
     "grade": false,
     "grade_id": "cell-dff56f438a8537a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Worksheet 08: Selection methods for generative and predictive models\n",
    "\n",
    "### Learning objectives\n",
    "By the end of this section, students will be able to:\n",
    "\n",
    "- Give examples of questions that can be answered by generative models and others that can be answered by predictive models.\n",
    "- Discuss how the research question being asked impacts the statistical modelling procedures.\n",
    "- Explain how regularized methods, such as lasso and ridge, can be used to estimate a predictive or a generative model.\n",
    "- Distinguish the selection properties of lasso and ridge penalties.\n",
    "- Discuss why the model obtained directly from lasso is not the most suitable model for generative modelling and how post-lasso is one way to address this problem.\n",
    "- Write a computer script to perform lasso/ridge and use it to predict new outcomes.\n",
    "- Write a computer script to perform post-lasso and use it to estimate a generative model.\n",
    "- Discuss post-inference problems (e.g., double dipping into the data set) and current practical solutions available to address these (e.g., data-splitting techniques).\n",
    "- Write a computer script to apply currently available practical solutions to post inference problems.\n",
    "- Discuss how the research question being asked impacts the communication of the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add787fc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d38763fd2082262b5d57d5334684a604",
     "grade": false,
     "grade_id": "cell-42bb9496684954db",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(glmnet)\n",
    "library(broom)\n",
    "library(leaps)\n",
    "library(repr)\n",
    "library(faraway)\n",
    "library(mltools)\n",
    "\n",
    "options(repr.plot.width=10, repr.plot.height=8)\n",
    "source(\"tests_worksheet_08.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e6a50",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43b792a27bee06ca42fe9adad2befcd7",
     "grade": false,
     "grade_id": "cell-b6a517078dce99d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# PART I: Regularized Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848ffe4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb86baaf254efec6f993dcf1527a93b2",
     "grade": false,
     "grade_id": "cell-6f048d81f2cffe21",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## In worksheet_07: \n",
    "\n",
    "### Select a model using *stepwise* algorithms\n",
    "\n",
    "- these are *greedy* algorithms \n",
    "\n",
    "- results depend on the order in which variables are selected \n",
    "\n",
    "- variables are either *in* (i.e., estimated coefficient different from zero) or *out* (i.e., estimated coefficient equal to zero)\n",
    "\n",
    "## In this worksheet:\n",
    "\n",
    "- can we use regularized methods to select a predictive model? and for a generative model?\n",
    "\n",
    "- can we use the selected model to make inference about the population?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69469f9e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "855ebce676152ebf9af8f9f7cc1b936c",
     "grade": false,
     "grade_id": "cell-219ec4f75a9ad8f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## PART I. Lasso "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145e2dd4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7dffad180f346e3dbe25c05e7aa4032a",
     "grade": false,
     "grade_id": "cell-05afee85a589325b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this first section you will use LASSO to select variables of a generative model. A problem of LASSO, and other regularized methods, is that the resulting estimators are **biased**. \n",
    "\n",
    "<font color='darkred'>**Bias estimators** are estimators whose sampling distributions are not centred on the true value of the parameter. </font> \n",
    "\n",
    "To study this problem, we are going to use a simulation to generate variables and a **known** model that relates them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb01a7b-3228-4ac6-89ce-5137b34e22f4",
   "metadata": {},
   "source": [
    "**Simulation Design**: here's what we are going to do: \n",
    "\n",
    "1. We are going to consider a response variable $Y$ and $p=3$ covariates. However, only 2 of the generated covariates will have an effect on $Y$. Hopefully, LASSO will select the 2 relevant ones.  \n",
    "\n",
    "2. Generate 100 observations (`n`) of each variable (the response and the 3 covariates) from a Normal distribution, with means equal to 0 for the covariates and the following mean for the response:\n",
    "\n",
    "$$\n",
    "E[Y|X_1, X_2, X_3] = 75X_1 - 5 X_2 + 0 X_3\n",
    "$$ \n",
    "\n",
    "> Therefore, the **true coefficients** are $\\beta_1=75$ and $\\beta_2=-5$. Note that $\\beta_3 = 0$, thus $X_3$ is not a relevant variable\n",
    "\n",
    "3. Use LASSO to select a model and store the coefficients of the selected model.\n",
    "\n",
    "4. Replicate (`rep`) this study 1,000 times. \n",
    "\n",
    "> Note that we are generating 1,000 datasets, all at once, and storing it in a tibble called `lasso_sim`. We will use the `map` function to apply a function to each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e8fa6c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d6e5a079e9636b0aa248c6f98b4692ee",
     "grade": false,
     "grade_id": "cell-95df2b5999161495",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing \n",
    "\n",
    "set.seed(20211113) # Do not change this.\n",
    "\n",
    "n <- 1000    # sample size\n",
    "rep <- 1000 # number of replications\n",
    "\n",
    "lasso_sim <- \n",
    "    tibble(\n",
    "        X1 = round(\n",
    "                rnorm(n * rep, 0, 10), \n",
    "                2),\n",
    "        X2 = round(\n",
    "                rnorm(n * rep, 0, 10), \n",
    "                2),\n",
    "        X3 = round(\n",
    "                rnorm(n * rep, 0, 20), \n",
    "                2),\n",
    "        Y = round(75 * X1 - 5*X2 + rnorm(n * rep, 0, 400),2)) %>% \n",
    "    mutate(replicate = rep(1:rep, n)) %>% \n",
    "    arrange(replicate) \n",
    "\n",
    "\n",
    "head(lasso_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e90e4ff",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "664a69547ab378ec3d288b1727ab607d",
     "grade": false,
     "grade_id": "cell-4665f4f34800f47c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.0**<br>\n",
    "{points: 1}\n",
    "\n",
    "Using the `lasso_sim` tibble, fit a LASSO model for each replicate.\n",
    "\n",
    "> Note: In the `glmnet()` function you can choose `family` like in `glm()`. The default option is `family = Gaussian`, which is used in this worksheet since the response is continuous. \n",
    "\n",
    "For simplicity, we'll use $\\lambda=30$ in all models. \n",
    "\n",
    "> However, in practice, it is not recommended to fit LASSO at a given lambda value. \n",
    "\n",
    "Store the models in a column named `lasso_models`. \n",
    "\n",
    "_Assign your data frame to an object called `lasso_study`. Your data frame should have four columns: `replicate`, `data`, and `lasso_model`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18767685",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7ff031f66814fb970e23e3fd2239164",
     "grade": false,
     "grade_id": "cell-aa46e5df61e9558b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lasso_study <- \n",
    "#     ... %>% \n",
    "#     ... %>% \n",
    "#     ... %>% \n",
    "#     mutate(\n",
    "#         lasso_model = ...(...,\n",
    "#                           ~...(.x %>% select(-Y) %>% as.matrix(), \n",
    "#                                   .x %>% select(Y) %>% as.matrix(), \n",
    "#                                   alpha = ..., \n",
    "#                                   lambda = ...)))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(as.data.frame(lasso_study), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86648684",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fb1ca8d662c7724d33a0a0939def35c",
     "grade": true,
     "grade_id": "cell-d68d670ab6c2496c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f7f81",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31e3f34feccbf5f26230145a4f3cee86",
     "grade": false,
     "grade_id": "cell-2a61e4f25256cc82",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1**<br>\n",
    "{points: 1}\n",
    "\n",
    "Extract the coefficient for `beta_1` from each `lasso_model` in the `lasso_study` tibble. Store the coefficients in a column name `lasso_beta1` in the same `lasso_study` tibble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a3cfd4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31898d3a60f9cc3d0c9c96ccc3c6060e",
     "grade": false,
     "grade_id": "cell-eb3b9bba09b060d0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lasso_study <- \n",
    "#     ... %>% \n",
    "#     ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(as.data.frame(lasso_study %>% select(-data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26531f67",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acbfcc90e8bdc527bad857eab44b4170",
     "grade": true,
     "grade_id": "cell-8ebd4cdf24d174b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef540c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd610d0bad97a6be8e20e78ed44c68e8",
     "grade": false,
     "grade_id": "cell-3472a426b731a695",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2**\n",
    "<br> {points: 1}\n",
    "\n",
    "Plot the sampling distribution of $\\hat{\\beta}_1$ obtained by Lasso.\n",
    "\n",
    "\n",
    "_Assign your plot to an object called `lasso_beta1_sampling_dist`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac61836",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5779b29e5d3766e625ebfffe7c02f9ca",
     "grade": false,
     "grade_id": "cell-21508cb2d3c1b17b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lasso_beta1_sampling_dist <- \n",
    "#     lasso_study %>% \n",
    "#     ggplot() + \n",
    "#     geom_...(aes(...), color='white') +\n",
    "#     geom_vline(xintercept = 75, color = 'red') + \n",
    "#     geom_text(aes(75, 110), label = \"True Value of the Parameter\", color = 'red') \n",
    "#     geom_text(aes(75, 80), label = \"True Value of\\n the Parameter\", color = 'red', size = 7) +\n",
    "#     theme(text = element_text(size = 18))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "lasso_beta1_sampling_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a92fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50ec81955c4cbe45da1abbbd41f39f8e",
     "grade": true,
     "grade_id": "cell-3b289632e05ad195",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90bc4e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7521b8bd065afa7364bb8c9f61ccefd",
     "grade": false,
     "grade_id": "cell-ae58776784170e6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "The sampling distribution of the lasso estimator of $\\beta_1$ is centered around the true $\\beta_1$.\n",
    "\n",
    "_Assign your answer to an object called `answer1.3`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9707ad82",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa50f54f572389dfbb43e449792eff46",
     "grade": false,
     "grade_id": "cell-cbc53e1b3025df42",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer1.3 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30fe597",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee31f307d67bf44c32c145edbe2476f2",
     "grade": true,
     "grade_id": "cell-2c1d0b19fb80ea91",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf344ca",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "475bbcb2d5d636c33cd7ac139747346b",
     "grade": false,
     "grade_id": "cell-70b6424c44d2cb6b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.4**<br>\n",
    "{points: 1}\n",
    "\n",
    "One way to correct the bias of the Lasso's estimated coefficients is to re-fit the model using LS and the variables selected by LASSO. In other words, we use LASSO only to select variables and ignore the estimated coefficients. We then re-estimate the coefficients of the selected variables using regular least squares. \n",
    "\n",
    "In the cell below we have done it for you. Here's what we did:\n",
    "\n",
    "1. Add a new column to `lasso_study` tibble, named `lasso_selected_covariates` with the covariates selected by LASSO (i.e., with coefficients different from 0).\n",
    "\n",
    "\n",
    "2. We fitted a linear model using `lm` (regular least square) and only the `lasso_selected_covariates`.\n",
    "\n",
    "\n",
    "3. We extracted $\\beta_1$ from the `lm` model, and saved it on a column called `ls_beta1`.\n",
    "\n",
    "Your job is to plot the sampling distribution of $\\hat{\\beta}_1$ obtained by the regular least square, using the variables selected by LASSO.\n",
    "\n",
    "_Assign your plot to an object called `post_lasso_lm_beta1_sampling_dist`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2e8a34",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e7151c2d9aeb829a0c8eff35b7338b7",
     "grade": false,
     "grade_id": "cell-6920e00dbec79884",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing\n",
    "\n",
    "lasso_study <- \n",
    "    lasso_study %>% \n",
    "    mutate(\n",
    "        lasso_selected_covariates = map(.x = lasso_model, \n",
    "                                        ~as_tibble(\n",
    "                                                as.matrix(coef(.x)),\n",
    "                                                rownames='covariate') %>%\n",
    "                                                filter(covariate != '(Intercept)' & abs(s0) > 10e-6) %>% \n",
    "                                                pull(covariate)),\n",
    "        ls_fit = map2(.x = data, .y = lasso_selected_covariates,\n",
    "                     ~lm(Y ~ ., data = .x[,c(.y, 'Y')])),\n",
    "        ls_beta1 = map_dbl(.x = ls_fit, ~tidy(.x) %>% filter(term == 'X1') %>% pull(estimate)))\n",
    "\n",
    "\n",
    "lasso_study %>% \n",
    "    select(-data, -lasso_model, -ls_fit) %>% \n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1707c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2db9c9581d5024293846a809b4343987",
     "grade": false,
     "grade_id": "cell-dd0e4b4d53066426",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# post_lasso_lm_beta1_sampling_dist <- \n",
    "#     lasso_study %>% \n",
    "#     ggplot() + \n",
    "#     geom_...(aes(...), color='white') +\n",
    "#     geom_vline(xintercept = 75, color = 'red') + \n",
    "#     geom_text(aes(75, 80), label = \"True Value of\\n the Parameter\", color = 'red', size = 7) +\n",
    "#     theme(text = element_text(size = 18))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "post_lasso_lm_beta1_sampling_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b095d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af36379b495980b6530cd27b9e4da78a",
     "grade": true,
     "grade_id": "cell-69a5a5d6f0125c49",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40216a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f0e6d3358a1ceb5d6ab8e154081b435",
     "grade": false,
     "grade_id": "cell-4db8971f16f54c5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## PART II: Inference after model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c6d03e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73ddd6501a22f9ce1f86d51a20827e2d",
     "grade": false,
     "grade_id": "cell-52b0432e6c14a90f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. Can we make inference using the selected models??\n",
    "\n",
    "An important topic learned in this course is how to make inference (e.g, calculate confidence interval and hypotheses tests) for a fixed model. However, when we apply a model selection algorithm, we are searching for the combination of variables that will give us the best model (according to a given metric). So the variables in our final models are not fixed; instead, they are selected adaptively based on **the data at hand**. \n",
    "\n",
    "Two questions arise then: \n",
    "\n",
    "1. Do these model selection algorithms affect the inference about the parameters of the model? \n",
    "\n",
    "2. Is the way we interpret the models still the same? \n",
    "\n",
    "In this section we'll investigate the first question when the forward selection method is used to select a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a3b93",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00429c4cb1ddfc1729567eb60fbeebe3",
     "grade": false,
     "grade_id": "cell-aa995988a3e3146f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Simulation Design**<br>\n",
    "\n",
    "Again, we are going to use a simulation study in order to be in full control of the true model that generates the data. Here's what we are going to do: \n",
    "\n",
    "1. We are going to consider a response variable $Y$ and $p=10$ independent variables. However, none of the generated variables will have an effect on $Y$. In other words, in this simulation study, we expect the intercept-only model to be better than any LR that includes any of the independent variables.\n",
    "\n",
    "\n",
    "2. Generate 100 observations (`n`) of each variable (the response and the 10 independent variables) from a Normal distribution.\n",
    "\n",
    "\n",
    "3. Apply the forward selection algorithm to select at most 3 variables among the 10 available. We restrict the size to 3 to shorten the computation time. Use the adjusted $R^2$ to compare models of different sizes.\n",
    "\n",
    "4. Use the selected model to make inference about the population. Recall that none of the independent variables is related to the response Y. However, due to randomness in the sample used, we may still (incorrectly) find a model that it's statistically better than the intercept only model! \n",
    "\n",
    "5. Replicate this study 1,000 times (`rep`) and compute the type I error rate. \n",
    "\n",
    "> Note that we are generating 1,000 datasets, all at once!! We will use the `map` function to apply a function to each dataset.\n",
    "\n",
    "*Run the cells below to generate the datasets.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72d705",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5dc0b2f3ce9215e4568223312d733f1",
     "grade": false,
     "grade_id": "cell-8196a2c8170de40f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing \n",
    "set.seed(20211113)\n",
    "\n",
    "n <- 100    # sample size\n",
    "p <- 10     # number of variables\n",
    "rep <- 1000 # number of replications\n",
    "\n",
    "means <- runif((p+1), 3, 10) # means for the Normal distribution \n",
    "                             # that will be used to generate \n",
    "                             # p covariates and a response Y   \n",
    "\n",
    "dataset <- as_tibble(\n",
    "  data.frame(\n",
    "    matrix(\n",
    "      round(rnorm((p + 1) * n * rep, \n",
    "            means, 10), 2), \n",
    "      ncol = p+1, \n",
    "      byrow = TRUE\n",
    "    )\n",
    "  ) %>% \n",
    "  rename(Y = X11) %>% \n",
    "  mutate(replicate = rep(1:rep, n)) %>% \n",
    "  arrange(replicate) \n",
    ")\n",
    "\n",
    "head(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd8d4d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1021b33f47f86cd6de08427ecf0cd7b5",
     "grade": false,
     "grade_id": "cell-99c152c3ff4d28bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dim(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc40c0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ab23f18acab835d957cd01819992c9c",
     "grade": false,
     "grade_id": "cell-038f4a539d529c3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.1 - Warm up**<br>\n",
    "{points: 1}\n",
    "\n",
    "To help you visualize the code abstraction, let's do a more intuitive exercise. \n",
    "Using the `dataset` tibble, fit one `lm` for each replicate using all 10 covariates to explain $Y$. Store the `lm` models in a column named `models`.\n",
    "\n",
    "_Assign your data frame to an object called `full_models`. Your data frame should have three columns: `replicate`, `data`, and `models`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534afbfd",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "86766ab99f82c294f0ccf2092e6a80cc",
     "grade": false,
     "grade_id": "cell-d5570a80d2c30190",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full_models <- \n",
    "#     ... %>% \n",
    "#     group_by(...) %>% \n",
    "#     nest() %>% \n",
    "#     mutate(models = map(...))\n",
    "\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "# Try exploring the columns of your data frame. \n",
    "# Check full_models$data[[1]] and full_models$models[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d43162",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32c0e51490fab08ed3f8b4769094907c",
     "grade": false,
     "grade_id": "cell-3e2a31ce11918efb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_models$models[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e65c4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "986feb95530e684d14e312866b9a389f",
     "grade": true,
     "grade_id": "cell-a4f7c92013fb0e66",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd12db00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ff34c50145946f94357b172504c9eb53",
     "grade": false,
     "grade_id": "cell-7f2f7877c77c43b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To help speed things up, we created a function for you that receives a data frame, runs the forward selection algorithm to select at most 3 variables, and fit LS on the selected variables. \n",
    "\n",
    "*Read and run the cell below to create such a function.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6369059b-8954-4b1e-a8a5-23280f4e0b58",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db221033548638060c55d29167b7e2d2",
     "grade": false,
     "grade_id": "cell-45cd02979d22326a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "forward_selection_function <- function(dataset){\n",
    "    sel_model <- regsubsets(x = Y ~ ., \n",
    "                    nvmax = 3,\n",
    "                    data = dataset,\n",
    "                    method = \"forward\",\n",
    ")\n",
    "\n",
    "sel_model_summary <- summary(sel_model)\n",
    "    \n",
    "adj_r2_min = which.max(sel_model_summary$adjr2) \n",
    "selected_var <- names(coef(sel_model, adj_r2_min))[-1]\n",
    "data_subset <- dataset %>% select(all_of(selected_var),Y)\n",
    "\n",
    "selected_model <- lm(Y ~ .,\n",
    "  data = data_subset\n",
    ")\n",
    "    return(selected_model)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e82f1ef-0dc7-494d-a25f-2ce5a7e5d8e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab441627e7c1d8fc1065a593d2bda6c4",
     "grade": false,
     "grade_id": "cell-50027fa08dcbf86b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Question 2.2**<br>\n",
    "{points: 1}\n",
    "\n",
    "The function `forward_selection_function` will be used to select and fit a model on a given data set using LS. We will then compare the selected model to the intercept only model using an $F$-test. Which null hypothesis will be tested:\n",
    "\n",
    "**A**. The coefficient of the first variable selected equals zero.\n",
    "\n",
    "**B**. The coefficient(s) of all selected variables equal zero.\n",
    "\n",
    "**C**. The selected variables equal zero.\n",
    "\n",
    "**D**. The intercept equals zero.\n",
    "\n",
    "*Assign your answer to an object called answer2.2. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"`, surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0901396-60f7-486c-bba6-beeafa2c42e8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "759d66063358543d353e8e5aa5f31cd3",
     "grade": false,
     "grade_id": "cell-03b617e11f90e205",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer2.2 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d163bc-fc05-4e6d-b011-83a71131e339",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50eb00d8849c26c7d14535cda57f0e44",
     "grade": true,
     "grade_id": "cell-725cbb37dbd83df9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8eee59",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c690b6ac4d1e4156a32aacbf35a9e2c",
     "grade": false,
     "grade_id": "cell-e2ca8b6be7d1c675",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3**<br>\n",
    "{points: 1}\n",
    "\n",
    "Using the function `map`, apply the `forward_selection_function` to each generated dataset in the tibble `dataset`, identified by the variable `replicate`. Store each fitted model in a column named `fs_model`. \n",
    "\n",
    "> Note that there are 1000 fitted models, one for each dataset generated!! \n",
    "\n",
    "Then, use the function `map_dbl` to compare each selected model to the intercept only model and extract the $p$-value of each $F$-test. Store the 1000 $p$-values in a column named `F_pvalue`.\n",
    "\n",
    "_Assign your data frame to an object called `forward_selection_F`. Your data frame should have four columns: `replicate`, `data`, `fs_model`, and `F_pvalue`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a70bba",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fef74d7079570af1852559e7421529a2",
     "grade": false,
     "grade_id": "cell-bf37cd17c298bbb8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# forward_selection_F <- \n",
    "#     ... %>% \n",
    "#     group_by(...) %>% \n",
    "#     nest() %>% \n",
    "#     mutate(\n",
    "#         ... = map(...), \n",
    "#         ... = ..._dbl(...)\n",
    "#     )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(as.data.frame(forward_selection_F), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e605b8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8daa5eaec7a07178aa9e4f259689f6ba",
     "grade": true,
     "grade_id": "cell-eabe9532c5e44b6d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcec61e4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2727310ec1167c634f7f0e45cbe151fb",
     "grade": false,
     "grade_id": "cell-c4f15d48f178784a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.4** \n",
    "<br> {points: 1}\n",
    "\n",
    "Knowing that none of generated independent variables are relevant to model $Y$, what proportion of tests would you expect to wrongly reject the null hypothesis that the coefficients of all the selected variables are zero? Consider the significance level of 5%.\n",
    "\n",
    "_Assign your answer to an object called `nominal_type_I_error`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259555f8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "295db2ccd2742ff13fb194a4fe1be60d",
     "grade": false,
     "grade_id": "cell-beba772a72681900",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# nominal_type_I_error <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "nominal_type_I_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013daa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e440f361c2e4df448e3db955091d733",
     "grade": true,
     "grade_id": "cell-8d98c976a828e040",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc7c7e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b40e5fc8e740a39e9ad555c3a2eb450c",
     "grade": false,
     "grade_id": "cell-ccc6a385e1043ed0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.5** \n",
    "<br> {points: 1}\n",
    "\n",
    "Check the proportions of $p$-values computed from the $F$-tests stored in the `forward_selection_F` tibble that are below the 5% significance level. \n",
    "\n",
    "_Assign your answer to an object called `forward_selection_type_I_error`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a08f82-a78b-45fe-89a6-46c2bfe33b90",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4923a0444dd528dc82b7d7bb43f56fca",
     "grade": false,
     "grade_id": "cell-2fa4716ac32bbaf7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# forward_selection_type_I_error <- \n",
    "#     ... %>% \n",
    "#     ungroup() %>% \n",
    "#     summarise(...(... < 0.05)) %>% \n",
    "#     pull()\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "forward_selection_type_I_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6bf221",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74ceb11fc39217c180517393e604cc0d",
     "grade": true,
     "grade_id": "cell-6c32bbee9d728156",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.5()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ad366c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c5b24627d835da014f4b2f680192529",
     "grade": false,
     "grade_id": "cell-d34cab1fa0787324",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2. The double use of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8775dd9f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac6a407688a2d911c26ce396a9b95398",
     "grade": false,
     "grade_id": "cell-e7302f3b294124f7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The Type I Error rate from the tests run using the fitted selected models was significantly higher than the nominal level of 5%. Why? \n",
    "\n",
    "Well, if we are looking for the most relevant covariates in a dataset, it is not surprising that we frequently find these covariates significant. In our case above, the *F-statistic* compares the reduction of SSR after adding the selected variables to an intercept-only model. But the variables selected were those that reduced the SSR (or increased the adjusted $R^2$) **in the sample at hand**. Hence, we have a much higher chance of wrongly rejecting $H_0$.  \n",
    "\n",
    "**The problem**: we are using the **same sample** to find the variables and fit the model. \n",
    "\n",
    "**A possible solution**: what if we split the dataset into two parts, one used for model selection and the other one used for inference? Would that solve the problem? \n",
    "\n",
    "Let's investigate! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043329f5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3037f43016406cc724efe5cb6793b9a",
     "grade": false,
     "grade_id": "cell-1a771305759350ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.0** \n",
    "<br> {points: 1}\n",
    "\n",
    "In this exercise we are again going to use the tibble `dataset`. But this time we are going to split our dataset into two parts. We are going to use one part to select a model, and the other part for inference. Since the sample sizes has changed, to compare strategies, we'll also fit the selected model and test it on the first set.\n",
    "\n",
    "> For this exercise, let's split the dataset in half. Note that other options are possible.\n",
    "\n",
    "Here's what you need to do: \n",
    "\n",
    "1. Using the first 50 observations, run the forward selection algorithm to select at most 3 variables and fit a LS on the selected variables. Store the selected model in `fs_model` column. \n",
    "\n",
    "\n",
    "2. Run an $F$-test to compare the selected model to an intercept only model and extract the $p$-value. Store the 1000 values in a column called `F_fs`.\n",
    "\n",
    "\n",
    "3. Fit the model selected in Step 1 using the 50 remaining observations and save it in a column named `inference_model`. Also, extracts the $p$-value of the $F$-test for the `inference_model` and stores it in a column called `F_pvalue`. \n",
    "\n",
    "> Note that using the `map` functions you can perform these steps at once for the 1000 datasets.\n",
    "\n",
    "_Assign your data frame to an object called `fs_error_split`. Your data frame should have 6 columns: `replicate`, `data`, `fs_model`, `F_fs`, `inference_model`, `F_pvalue`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e70736",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3d6c3be6ad8b2ce867091adc4e38caca",
     "grade": false,
     "grade_id": "cell-b544356ca3740453",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(20211113) # Do not change this.\n",
    "\n",
    "# fs_error_split <- \n",
    "#     ... %>% \n",
    "#     ... %>% \n",
    "#     ... %>% \n",
    "#     mutate(\n",
    "#         fs_model = ...(..., .f = function(d) forward_selection_function(d %>% head(50))), \n",
    "#         F_fs = ...,\n",
    "#         inference_model = map2(.x = ..., .y = ..., ~ update(.y, .~., data = .x %>% tail(50))), \n",
    "#         F_pvalue =  ...)\n",
    "#     )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "        \n",
    "head(fs_error_split) %>% \n",
    "    select(replicate, F_fs, F_pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e35bbe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b28e9c804a36560eb8eea36195915b09",
     "grade": true,
     "grade_id": "cell-87cd37c4793c4935",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e07955-9ffa-4112-afcd-43558926ae6a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9d5419a6eb732f4f1cce6cec056041d5",
     "grade": false,
     "grade_id": "cell-85ee6bf7f4767ba4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Question 3.1** \n",
    "<br> {points: 1}\n",
    "\n",
    "Check the proportions of $p$-value of the $F$-test in the `F_fs` column that are below the 5% significance level. Note that these tests were run using the the first split of the data used to select the model.\n",
    "\n",
    "> Hint: you've done something similar in **Question 2.5**\n",
    "\n",
    "_Assign your answer to an object called `fs_split1_type_I_error`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ac98d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9bf1783034bbbeb51bf3f4473b40ed79",
     "grade": false,
     "grade_id": "cell-d63bd5b3efb2ae77",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fs_split1_type_I_error <- ... \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "fs_split1_type_I_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c72122-3478-4fe4-b92e-a9e79bc22080",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60340242e937adc0422e50764609f1f7",
     "grade": true,
     "grade_id": "cell-1c5a6ffc1c5a7870",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce156766",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "27170873b59a7163c7661ba17dd07f46",
     "grade": false,
     "grade_id": "cell-d98b56dbc789635d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2** \n",
    "<br> {points: 1}\n",
    "\n",
    "Check the proportions of $p$-value of the $F$-test in the `F_pvalue` column that are below the 5% significance level. Note that these tests were run using the the second split of the data that was *not used* to select the model.\n",
    "\n",
    "\n",
    "_Assign your answer to an object called `fs_split2_type_I_error`. Your answer should be a single number._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05d377e-0e60-4396-9be8-9a7f6cd33635",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "592b4065cc1e2d751e6777f22506753d",
     "grade": false,
     "grade_id": "cell-d647eb0fcdf010b7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fs_split2_type_I_error <- ... \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "fs_split2_type_I_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d7e65d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71553681d26c1f016580f024f752a7fa",
     "grade": true,
     "grade_id": "cell-9b2666ff7cd4089f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278e615d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a66862a647e356c9780e04eaaf7f369",
     "grade": false,
     "grade_id": "cell-851de6eae8846cad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "If we split the data and use different part for model selection and inference, the type I error of the F-test after the forward selection is close to the significance level. \n",
    "\n",
    "_Assign your answer to an object called `answer3.3`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1316403a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "51cf6ec611d256f7a83177cca319ae94",
     "grade": false,
     "grade_id": "cell-f1a4e23880603605",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer3.3 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4f30c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01bd593914a1999f5d2beaea69f42b71",
     "grade": true,
     "grade_id": "cell-b588d3c3d475102a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_3.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda2121a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e862e91d5bed6ccf90ce0362edd1d5a",
     "grade": false,
     "grade_id": "cell-fb759982412336e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Class discussion \n",
    "Contrast the `forward_selection_type_I_error` and `nominal_type_I_error`. Are they similar? Why do you think this is happening. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765c4eb-52ad-417d-b180-453baf7acb93",
   "metadata": {},
   "source": [
    "<font color='darkred'>The post-inference problem in models selected through forward selection, as examined in this simulation study, *also occurs with LASSO*. </font>\n",
    "\n",
    "In the tutorial, you will address the problem by splitting the dataset -- one part for selecting variables using LASSO and the other for fitting the model for inference. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c7c05b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cab25e88802a5e4a71f93a1b032b16d6",
     "grade": false,
     "grade_id": "cell-47eca90d66532852",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "#### Lasso has two problems:\n",
    "\n",
    "- **Biased estimators**: we can take care of this by fitting regular least squares on the variables selected by Lasso. This approach is called **post-lasso**.\n",
    "\n",
    "- **Post-inference**: fitting a LS regression after LASSO, we are using the data to select the variables as well as to conduct inference. We cannot rely on the inference given by the `lm`, unless we split the data to take care of this problem.\n",
    "\n",
    "#### Post-inference problem:\n",
    "\n",
    "- we can not use the same data to select variables of the model and to conduct inference (\"double dipping\"). \n",
    "\n",
    "- the inference results given by the `lm` are not valid (as seen in the first part of the worksheet). \n",
    "\n",
    "- if we split the data, we can use one part to select and the other part to estimate and build tests.\n",
    "\n",
    "- more sophisticated methods have been proposed to address this problem (beyond the scope of this course).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
