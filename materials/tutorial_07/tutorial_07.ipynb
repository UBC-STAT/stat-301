{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "241226ca729e2a495e8157028caca2de",
     "grade": false,
     "grade_id": "cell-3410823c297a225b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **Tutorial 07: Goodness of Fit beyond MLR and Stepwise Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "734994bff7e5fdb0a28e125e46b2f98b",
     "grade": false,
     "grade_id": "cell-34b6d6e1de870f0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Lecture and Tutorial Learning Goals:\n",
    "After completing this week's lecture and tutorial work, you will be able to:\n",
    "\n",
    "1. List model metrics that are suitable for evaluation of a statistical model developed to make inferences about the data-generating mechanism (e.g., $R^2$, $\\text{AIC}$, Likelihood ratio test/$F$-test), their strengths and limitations, as well as how they are calculated.\n",
    "2. Identify appropriate goodness-of-fit metrics for MLR, logistic and Poisson regressions.\n",
    "3. Compute appropiate residuals of logistic and Poisson regressions.\n",
    "4. Explain how an $F$-test to compare nested models can be used as a variable selection methods.\n",
    "5. Write a computer script to calculate these model metrics. Interpret and communicate the results from that computer script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96fe59cd73402ba806ee67272b399b96",
     "grade": false,
     "grade_id": "cell-75c97cc6762ecd03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading Libraries\n",
    "\n",
    "library(MASS)\n",
    "library(broom)\n",
    "library(tidymodels)\n",
    "library(repr)\n",
    "library(mltools)\n",
    "library(leaps)\n",
    "library(tidyverse)\n",
    "library(modelr)\n",
    "source(\"tests_tutorial_07.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "550360f7ca2cd3036bb7b99b7d0e8c6a",
     "grade": false,
     "grade_id": "cell-9b8b52ce313503af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Stepwise Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd8a6eac5974ba378b3aae110be5c42f",
     "grade": false,
     "grade_id": "cell-f968abd3ee677d53",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In this tutorial we will focus on selecting a subset of variables to include in a predictive model. Do we actually need all the available input variables? Some datasets contain *many* variables, but not all of them are relevant. To decide if a variable (or set of variables) is relevant, we need to choose an evaluation metric. \n",
    "\n",
    "The evaluation metric used depends on the goal of the analysis. So, what is your goal? *Inference or prediction?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "431007b83adb973a4ff5ad19c54e6f8f",
     "grade": false,
     "grade_id": "cell-f47e7121e611c1e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Variable selection for generative models\n",
    "\n",
    "In previous worksheets, we learned different selection and estimation methods when the goal is to *estimate and make inferences about* the model that generated the data. We referred to these models as *generative models*.\n",
    "\n",
    "For a LR with an intercept and estimated by LS:\n",
    "\n",
    "- The $\\mathbf{R^2}$, coefficient of determination, can be used to measure the part of the variation in the response explained by the estimated model\n",
    "\n",
    "\n",
    "- The **Adjusted $\\mathbf{R^2}$** can be used to compare the fit of estimated models of different sizes\n",
    "\n",
    "\n",
    "- The **MSE** (based on in-sample data) can be used to compare the observed values with those predicted by the estimated model  \n",
    "\n",
    "\n",
    "- These $\\mathbf{F}$ tests can be used to select variables by comparing nested models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d5a56fabfc102bb370ab4bb02058cba",
     "grade": false,
     "grade_id": "cell-9dac937e51857aca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Variable selection for predictive models\n",
    "\n",
    "How do we evaluate the predictive performance of a model? For regression models, two common choices are:\n",
    "\n",
    "- **Mean Squared Error (MSE)**: $$\\text{MSE}_{\\text{test}} = \\frac{1}{n_{\\text{new}}}\\sum_{i=1}^{n_{\\text{new}}}(y^{\\text{new}}_i - \\widehat{y}^{\\text{new}}_i)^2$$\n",
    "<font color='darkred'>where $y^{\\text{new}}_i$ are **new responses from the test set**</font>, $\\widehat{y}^{\\text{new}}_i$ are the predicted values using the LR estimated with the training data but with the input data from the test set, and $n_{\\text{new}}$ is the number of data points in the test set. You *do not want* to use the data in the training set to evaluate your model. \n",
    "\n",
    "- **Root Mean Squared Error (RMSE)**: this is the square root of MSE.\n",
    "$$\\text{RMSE}_{\\text{test}} = \\sqrt{\\text{MSE}_{\\text{test}}} = \\sqrt{\\frac{1}{n_{\\text{new}}}\\sum_{i=1}^{n_{\\text{new}}}(y^{\\text{new}}_i - \\widehat{y}_i)^2}$$\n",
    "Once again, remember that $y_i$ are observations in the test set and weren't used to train the model. \n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "Another possibility, not really common for prediction is the $R^2$.\n",
    "- **$R^2$**: remember that $R^2$ can be computed for new responses in a test set.\n",
    "$$R^2 = cor(\\boldsymbol{y}^{\\text{new}}, \\widehat{\\boldsymbol{y}}^{\\text{new}})$$\n",
    "Some functions compute the $R^2$ from a validation set or using cross-validation (perhaps seen in other courses). However, note that it is ***no longer the coefficient of determination***. It measures the correlation between the true and the predicted responses *in a test set*.   \n",
    "\n",
    "<br> \n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "There are other common metrics that have been proposed to approximate the *test MSE* but are computed with the training set only. You can use these measures to select variables of predictive models, even without using a test set.\n",
    "\n",
    "- $C_p$:\n",
    "\n",
    "- $AIC$:\n",
    "\n",
    "- $BIC$: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "513c4aa104af9e2a1a551eee8386fb32",
     "grade": false,
     "grade_id": "cell-aa844e3860a3dcbe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Dataset: the [Ames `Housing` dataset](https://www.kaggle.com/c/home-data-for-ml-course/)\n",
    "\n",
    "In this section, we will work with a real estate dataset, the [Ames `Housing` dataset](https://www.kaggle.com/c/home-data-for-ml-course/), compiled by Dean De Cock. It has 79 input variables on different characteristics of residential houses in Ames, Iowa, USA, that can be used to predict the property's final price, `SalePrice.` We will use the following continuous input variables:\n",
    "\n",
    "- `LotFrontage`: Linear $\\text{ft}$ of street connected to the house.\n",
    "- `LotArea`: Lot size in $\\text{ft}^2$.\n",
    "- `MasVnrArea`: Masonry veneer area in $\\text{ft}^2$.\n",
    "- `TotalBsmtSF`: Total $\\text{ft}^2$ of basement area.\n",
    "- `GrLivArea`: Above grade (ground) living area in $\\text{ft}^2$.\n",
    "- `BsmtFullBath`: Number of full bathrooms in the basement.\n",
    "- `BsmtHalfBath`: Number of half bathrooms in the basement.\n",
    "- `FullBath`: Number of full bathrooms above grade.\n",
    "- `HalfBath`: Number of half bathrooms above grade.\n",
    "- `BedroomAbvGr`: Number of bedrooms above grade (it does not include basement bedrooms).\n",
    "- `KitchenAbvGr`: Number of kitchens above grade.\n",
    "- `Fireplaces`: Number of fireplaces.\n",
    "- `GarageArea`: Garage's area in $\\text{ft}^2$.\n",
    "- `WoodDeckSF`: Wood deck area in $\\text{ft}^2$.\n",
    "- `OpenPorchSF`: Open porch area in $\\text{ft}^2$.\n",
    "- `EnclosedPorch`: Enclosed porch area in $\\text{ft}^2$.\n",
    "- `ScreenPorch`: Screen porch area in $\\text{ft}^2$.\n",
    "- `PoolArea`: Pool area in $\\text{ft}^2$.\n",
    "\n",
    "The following variables will be used to construct a variable `ageSold`\n",
    "- `YearBuilt`: Original construction date.\n",
    "- `YrSold`: Year sold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "617c92c4ab25c5405f61960f761d0810",
     "grade": false,
     "grade_id": "cell-0e57653584382931",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run this code to prepare a working dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11e0c4914fc41c304bc96aa0cecf32ff",
     "grade": false,
     "grade_id": "cell-95e16218a5e51a83",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "housing <- \n",
    "    read_csv(\"data/Housing.csv\") %>%\n",
    "    mutate(ageSold = YrSold - YearBuilt) %>%\n",
    "    select(LotFrontage, LotArea, MasVnrArea, TotalBsmtSF,\n",
    "           GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, \n",
    "           HalfBath, BedroomAbvGr, KitchenAbvGr, Fireplaces,\n",
    "           GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, \n",
    "           ScreenPorch, PoolArea, ageSold, SalePrice) %>%\n",
    "    drop_na() %>%\n",
    "    filter(LotArea < 20000)\n",
    "\n",
    "str(housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95b9fa0922e3b237acb8d573ae5b1b88",
     "grade": false,
     "grade_id": "cell-04b81214318292af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "We'll first split this dataset into a training and a test set using the tidymodels package.\n",
    "\n",
    "Run this code to split the dataset `housing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ee12bac541f371f565674772ca6e9f0",
     "grade": false,
     "grade_id": "cell-7008e2fc78a22fcf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#run this cell\n",
    "set.seed(1234)\n",
    "\n",
    "housing_split <- \n",
    "    housing %>%\n",
    "    initial_split(prop = 0.6, strata = SalePrice)\n",
    "\n",
    "training_housing <- training(housing_split)\n",
    "testing_housing <- testing(housing_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8292db06e20e17bcb66e2a4be7c71f3e",
     "grade": false,
     "grade_id": "cell-ff62a9f7bb684c78",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "head(training_housing, 3)\n",
    "cat('\\nTraining data has', nrow(training_housing), 'rows.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9704edc95d369e04659fa816a93d125c",
     "grade": false,
     "grade_id": "cell-4bea34ca87ec85f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# You don't want to even look at the test data. \n",
    "# Set it aside.\n",
    "\n",
    "cat('\\nTest data has', nrow(testing_housing), 'rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7bdd7c2c72156524fb8ea90e7c179a9",
     "grade": false,
     "grade_id": "cell-cfd5f798bca9908d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.1 Estimating an MLR and Predicting\n",
    "\n",
    "In DSCI100, you have learned how to use `tidymodels` to build a model and use it to predict. You can write your own script to perform these steps or use a `linear_reg` model specification with the `lm` engine in `tidymodels`. Below, you will use the usual tidymodels workflow to predict each house's sale price in the test set.\n",
    "\n",
    "Run this code to fit a MLR using `tidymodels` and call it `housing_full_tidy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b64d3bf69110a1fee952b80f614d7514",
     "grade": false,
     "grade_id": "cell-9f38c52756dd7dfe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lm_spec <- \n",
    "    linear_reg() %>% \n",
    "    set_engine(\"lm\") %>% \n",
    "    set_mode(\"regression\")\n",
    "\n",
    "lm_recipe <- recipe(SalePrice ~ ., data = training_housing)\n",
    "\n",
    "housing_full_tidy <- \n",
    "    workflow() %>% \n",
    "    add_recipe(lm_recipe) %>% \n",
    "    add_model(lm_spec) %>% \n",
    "    fit(data = training_housing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "690ad302db9c8e93f181e935f5d5758c",
     "grade": false,
     "grade_id": "cell-55a3f1be685733c0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Recall that we can extract the estimated coefficients from the workflow using the `extract_git_parsnip()` function. We then use `tidy()` to arrange them into a data frame.\n",
    "\n",
    "Run the code below to get the estimated coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74309f636afa7d828d8436aae33ea439",
     "grade": false,
     "grade_id": "cell-252bbfc230614233",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "coeffs <- \n",
    "    housing_full_tidy %>% \n",
    "    extract_fit_parsnip() %>% \n",
    "    tidy()\n",
    "\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a1ba1d360d8df2466f1742d2c55ceab",
     "grade": false,
     "grade_id": "cell-92225ba1bcfd49ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Question 1.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "Write your own code and compare the results obtained with those using `tidymodels`\n",
    "\n",
    "- Fit a MLR using data from `training_housing`. Store the output in an object named `housing_full_OLS`.\n",
    "\n",
    "- Use `tidy()` to obtain a summary table of the estimated `housing_full_OLS`. Call it `housing_full_OLS_results`.\n",
    "\n",
    "- Use the `modelr::add_predictions()` and `housing_full_OLS` to obtain the **out-of-sample predictions** for `testing_housing`. Store them as a new column in `testing_housing` called `pred_full_OLS`.\n",
    "\n",
    "> **Note**: if you enter the input variables manually in `lm`, follow the order in the dataset. This is not important for results, just to pass the tests of autograding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e94b754dc1a3d2a9328be1270da7014",
     "grade": false,
     "grade_id": "cell-d9c668e2b532fbc7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code goes here. \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "housing_full_OLS_results\n",
    "head(testing_housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "985d3e7d65202bd88cda1c7eb71f814a",
     "grade": true,
     "grade_id": "cell-976fe40dfb808a95",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "626b090df4f538789d031bf005b69900",
     "grade": false,
     "grade_id": "cell-018c67dd165c7d79",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "**Question 1.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "Running the code below, you can check whether the estimated coefficients obtained using the `tidymodels` workflow are the same as those obtained using your code. \n",
    "\n",
    "Are they the same? \n",
    "\n",
    "*Assign your answer to an object called `answer1.1`. Your answer should be either `\"true\"` or `\"false\"`, surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ede6907b2940720044e6d40fd26d2ae7",
     "grade": false,
     "grade_id": "cell-a0f01e4daa5d0b5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell to compare the estimates\n",
    "tibble(estimates_your_code = housing_full_OLS_results$estimate,\n",
    "       estimate_tidymodels = coeffs$estimate, \n",
    "       difference = housing_full_OLS_results$estimate - coeffs$estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff7ecf8f8d17c86aafab62895af21a5e",
     "grade": false,
     "grade_id": "cell-8ea2dda367d4fd62",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# answer1.1 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba1b7c856e07b2b38022a59cb3622bcc",
     "grade": true,
     "grade_id": "cell-8f424ba76018ad76",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1071c41a5cbaa5a6ba8c53bf778e7c9",
     "grade": false,
     "grade_id": "cell-8cd6efd0c1c53d7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "We can use the function `metrics()` to compute the root mean squared error, the $R^2$ and the mean absolute error for the predicted `SalePrice` of the test samples. \n",
    "\n",
    "Alternatively, we can write our own code to compute these measures. In this exercise, write your code to calculate the RMSE. \n",
    "\n",
    "Create a tibble, called `housing_RMSE_models` to store the computed RMSE. We will later compare it with the RMSE of a reduced model. The new tibble will have 2 columns:\n",
    "\n",
    "- `Model`: Name of the estimated model from which we will obtain the prediction accuracy.\n",
    "- `RMSE`: The $\\text{RMSE}_{\\text{test}}$ corresponding to the estimated model.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "801ca3eb38d27db08bd46d9c03816bea",
     "grade": false,
     "grade_id": "cell-a325bd988a79aa49",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. compute the RMSE (the template below is for inspiration, but you can calculate it\n",
    "#    any way you want. \n",
    "\n",
    "# rmse_full <-\n",
    "#     ...\n",
    "#     ...\n",
    "#     ...\n",
    "#     ...\n",
    "\n",
    "# 2. store it in a tibble:\n",
    "\n",
    "# housing_RMSE_models <- tibble(\n",
    "#   Model = \"OLS Full Regression\",\n",
    "#   RMSE = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "housing_RMSE_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce61c2ec25c0b47ce11523e52ab3df82",
     "grade": true,
     "grade_id": "cell-bd5363bd8cd05844",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85cf04d74feec09bbef76e71dd2ab38b",
     "grade": false,
     "grade_id": "cell-c3b15096f7ada01e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Run the code below to compare the results with those obtained with `metics()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1734f4df3a6d881745dce70d86a5c610",
     "grade": false,
     "grade_id": "cell-734c7db6f61e879a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_test_metrics <- \n",
    "    testing_housing %>%\n",
    "    metrics(truth = SalePrice, estimate = pred_full_OLS)\n",
    "\n",
    "housing_test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54e16b5b0255893fb7e6f6b3f9e29585",
     "grade": false,
     "grade_id": "cell-bb7e72eaeb186a76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font color='darkred'>**Tip:** In practice, refrain from creating your own functions if a reliable package with the desired function is available. This not only saves time but also minimizes the risk of bugs and errors, as these functions are widely tested.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0fa68cb8ea93bc079d8ceeedd8eaf001",
     "grade": false,
     "grade_id": "cell-8f8a4c8fe2b330e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1.2 An automated procedure for model selection\n",
    "\n",
    "When we don't know which variables should be included in the model, ideally, you want to select the best model out of *all possible models* of all possible sizes. \n",
    "\n",
    "For example, if the dataset has 2 explanatory variables $X_1$ and $X_2$, there are 4 models to compare: \n",
    "    \n",
    "1. an intercept-only model; \n",
    "2. a model with only $X_1$; \n",
    "3. a model with only $X_2$; and \n",
    "4. a model with both $X_1$ and $X_2$. \n",
    "\n",
    "Unfortunately, the number of *all possible* models becomes too large rapidly, even for a small subset of variables. In fact, from a set of $p$ variables, we can fit a total of $2^p$ different models. For example, if $p = 20$ (i.e., 20 available explanatory variables), we would need to evaluate more than a million models. \n",
    "\n",
    "There are methods to search more efficiently for a good model (although it may not find the \"best\" one out of all possible):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60a2072ba3dc9170bb6f8999c498fadb",
     "grade": false,
     "grade_id": "cell-407d22a6a1e202f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2.1 Forward selection algorithm\n",
    "Image from [ISLR](https://www.statlearning.com)\n",
    "![](https://github.com/UBC-STAT/stat-301/blob/master/supplementary-material/img/forward.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c754c33051a1988f0d596f18378e303",
     "grade": false,
     "grade_id": "cell-fb0d05896adad813",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "1. **Step 1:** Start with the intercept-only model: $y_i = \\beta_0 + \\varepsilon_i$ (remember that in this case, $\\hat{\\beta}_0 = \\bar{y}$ from the training samples, so $\\hat{y} = \\bar{y}$ for any observation from the training or the test set)\n",
    "\n",
    "2. **Step 2:** Evaluate all models of size 1, choose the \"best\" model with 1 covariate (based on RSS, equal size models), and call it $\\mathcal{M}_1$. \n",
    "\n",
    "3. **Step 3** *Starting with the best size 1 model*, add 1 variable to create a (expanded) model of size 2. Repeat for all remaining variables and evaluate all expanded models of size 2. Choose the best model of size 2 (based on RSS) and call it $\\mathcal{M}_2$. (*Note that there are more models of size 2 that we are not evaluating since 1 variable has already been chosen in the previous step*).\n",
    "\n",
    "\n",
    "$\\quad \\quad \\vdots$ \n",
    "\n",
    "continue until you reach a predetermined model size or the full model, $\\mathcal{M}_p$. Note that the full model is unique. \n",
    "\n",
    "\n",
    "Now, we have to select the best out of the $p$ selected models: \n",
    "- $\\mathcal{M}_1$ (the best model of size 1);\n",
    "- $\\mathcal{M}_2$ (the best-expanded model of size 2),\n",
    "- $\\ \\ \\vdots$\n",
    "- $\\mathcal{M}_p$ (the full model of size $p$). \n",
    "\n",
    "Unfortunately, we cannot use the RSS to compare models of different sizes. In fact, the metric will depend on the study goal. For generative models, the adjusted $R^2$ can be helpful. If the objective is predictions, then the test MSE, $C_p$, AIC, or BIC are useful.\n",
    " \n",
    "You can learn more about these measures in [ISLR](https://www.statlearning.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47fba39ea0fa6be89c9d21375475f315",
     "grade": false,
     "grade_id": "cell-de41449632c6590f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Other selection procedures include:\n",
    "\n",
    "- **Backward selection**: start with the full model and remove variables, one at a time\n",
    "\n",
    "\n",
    "- **Hybrid selection**: after adding a variable, the method may also remove variables \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b1f325adb8a94d97755b962ddb9ef3b3",
     "grade": false,
     "grade_id": "cell-bf5842286faba0c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2.2 Selecting a smaller model in R\n",
    "\n",
    "The OLS model estimates a generative model using all input variables. However, as we see from the results table, not all the terms in this regression are statistically significant, and this may not be the best predictive model either. You might want to select a smaller subset of variables that better explain the variation in `SalePrice` or to predict. In the following questions, you will use the forward selection algorithm to select a smaller model. We will compute different metrics to examine different types of models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed9dea9591c60cc63dbf42b9160bce9e",
     "grade": false,
     "grade_id": "cell-195b5904f0f0cd43",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### **R functions**\n",
    "\n",
    "Both the **forward** and **backward** selection algorithms are implemented in R by the function `regsubsets()` from library `leaps`. \n",
    "\n",
    "- The argument `x` of `regsubsets()` is analogous to `formula` in `lm()`. \n",
    "\n",
    "- The argument `nvmax` indicates the maximum number of variables to be used in the variable selection.\n",
    "\n",
    "This function identifies subsets of input variables that provide the best model for different model sizes and then selects the best among those.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61d66b3879afb69659da8805c46181c0",
     "grade": false,
     "grade_id": "cell-c5d137288b408d5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Forward selection in the `housing`  dataset**\n",
    "\n",
    "Let's select some of the input variables in the `housing` dataset using the **forward selection** algorithm, aiming for a strong generative model. \n",
    "\n",
    "Create one object using `regsubsets()`with `training_housing`: `housing_forward_sel`. This object has to indicate  selected models for each model size, from **1 to 19 input variables** (check argument `nvmax`).\n",
    "\n",
    "*Run the code below to select the best nested models of each size*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27646a33c608bd3447257b7fc3040e8c",
     "grade": false,
     "grade_id": "cell-7b173b9bec803e9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_forward_sel <- regsubsets(x = SalePrice ~ ., nvmax = 19,\n",
    "                                  data = training_housing,\n",
    "                                  method = \"forward\")\n",
    "\n",
    "housing_forward_summary <- summary(housing_forward_sel)\n",
    "housing_forward_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34388314172355e331817ee369bce019",
     "grade": false,
     "grade_id": "cell-04e315d7f0efdfff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can see that: \n",
    "\n",
    "- variables are selected one at a time.\n",
    "\n",
    "- once the variable is in the model, it stays, and another variable is selected\n",
    "\n",
    "- the algorithm continues until it builds a model of size `nvmax`\n",
    "\n",
    "**Final selection**\n",
    "\n",
    "Out of the 19 possible models obtained with forward selection and stored in `housing_forward_sel`, we can select the best one in terms of its *goodness of fit*. \n",
    "\n",
    "Let's store and examine different evaluation metrics contained in `housing_forward_summary`. Construct a tibble called `housing_forward_eval`. This object should contain the following columns:\n",
    "\n",
    "- `n_input_variables`: the number of input variables in each selected model (from 1 to 19).\n",
    "\n",
    "- `RSQ`: the $R^2$ of each model\n",
    "\n",
    "- `RSS`: the RSS of each model\n",
    "\n",
    "- `ADJ_R2`: the adjusted $R^2$ of each model\n",
    "\n",
    "- `Cp`: the $C_p$ of each model\n",
    "\n",
    "- `BIC`: the Bayesian Information Criterion of each model\n",
    "\n",
    "*Run the following code to evaluate the best models of each size*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be546281fd2225efca8e044139641f0e",
     "grade": false,
     "grade_id": "cell-6790f3a767aece0e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing_forward_summary_df <- tibble(\n",
    "    n_input_variables = 1:19,\n",
    "    RSQ = housing_forward_summary$rsq,\n",
    "    RSS = housing_forward_summary$rss,\n",
    "    ADJ_R2 = housing_forward_summary$adjr2,\n",
    "    Cp = housing_forward_summary$cp,\n",
    "    BIC = housing_forward_summary$bic,\n",
    ")\n",
    "housing_forward_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "183548836cb4de6b57815100647d58ca",
     "grade": false,
     "grade_id": "cell-69bc1407080925bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You can see how the $R^2$ increases with more variables in the model. However, its adjusted version will start decreasing after 13 variables are selected. \n",
    "\n",
    "**The forward algorithm would select a generative model with 13 variables using the adjusted $R^2$**.\n",
    "\n",
    "**The forward algorithm would select a predictive model with 11 variables using BIC**.\n",
    "\n",
    "We can **visualize** how these measures change as variables are added to the selected model with the function `plot()`. \n",
    "\n",
    "Run this code to plot the $C_p$ of the models selected by the forward selection algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "91e334b3f38b41d3477b0abef88e5e08",
     "grade": false,
     "grade_id": "cell-0693a2cff89dfa39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot(summary(housing_forward_sel)$cp,\n",
    "     main = \"Cp for forward selection\",\n",
    "     xlab = \"Number of Input Variables\", \n",
    "     ylab = \"Rsq\",\n",
    "     type = \"b\",\n",
    "     pch = 19,\n",
    "     col = \"red\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61a486b5c1fc70d012c4c83e21c89f19",
     "grade": false,
     "grade_id": "cell-5b3fd20fb437c9de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### **Prediction performance of the selected predictive model**\n",
    "\n",
    "In this problem, you will select the model that minimizes the $C_p$. Once we have a selected model we can train it using `lm()` with the training dataset and use it predict values of the residences in the test set. \n",
    "\n",
    "Run this code to obtain the name of the variables selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e25506558711ed992aa22be4838d90b1",
     "grade": false,
     "grade_id": "cell-a841f211bf64e777",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cp_min = which.min(housing_forward_summary$cp) \n",
    "\n",
    "selected_var <- names(coef(housing_forward_sel, cp_min))[-1]\n",
    "selected_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f3b0f66ba514ff2d33e4722874dd46a3",
     "grade": false,
     "grade_id": "cell-67995940c0bcc135",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Run this code to subset only the predictors selected from the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85bd1b7ef061a546496cefdc22ff846b",
     "grade": false,
     "grade_id": "cell-943bb2d88f880089",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_subset <- \n",
    "    training_housing %>% \n",
    "    select(selected_var, SalePrice)\n",
    "\n",
    "testing_subset <- \n",
    "    testing_housing %>% \n",
    "    select(selected_var, SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e355ca6f774247c9156932c2a9c3c41c",
     "grade": false,
     "grade_id": "cell-93e95f38df759d47",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Run this code to train the selected models and use it to predict in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8844ca948175414b40c772173bda7ac2",
     "grade": false,
     "grade_id": "cell-05251bb3db6a3810",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Estimation\n",
    "\n",
    "housing_red_OLS <- lm(SalePrice ~ ., data = training_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f28eaaa574bb5b466d2c798fbc3bc69a",
     "grade": false,
     "grade_id": "cell-e6c3ceb269ad8bd1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "Use the new reduced predictive model, `housing_red_OLS`, to predict the response in the test set `testing_subset`. Use the resulting predictive values to compute the error and the $\\text{RMSE}_{\\text{test}}$ of the predictive values. Add this metric as another row in the tibble `housing_RMSE_models` and store the expanded `housing_RMSE_models` in an object called `housing_RMSE_models_expanded`. Identify the new row as `\"OLS Reduced Regression\"` (in column `Model`) and enter the corresponding $\\text{RMSE}_{\\text{test}}$ in the column `RMSE`.\n",
    "\n",
    "> Note: since you are adding a row to an existing object, you may need to restart the kernel or rerun the cell with the original data frame to avoid extra concatenation.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f105460fc7308a503b51b2c3284fda89",
     "grade": false,
     "grade_id": "cell-b0bc48dc5dfd91bc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [You are all grown up now, do your own coding :) ]\n",
    "\n",
    "# rmse_red <- ... (several rows of code are needed)\n",
    "\n",
    "\n",
    "# housing_RMSE_models_expanded <- \n",
    "#     bind_rows(\n",
    "#         housing_RMSE_models,\n",
    "#         tibble(Model = \"OLS Reduced Regression\",\n",
    "#                RMSE = ...)\n",
    "#     )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "housing_RMSE_models_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9cab57a214c39fae31fc78412acca26",
     "grade": true,
     "grade_id": "cell-25b2040355c36cb8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "897843eb672ea8b9b974e9cca41072dd",
     "grade": false,
     "grade_id": "cell-897661ec25ffa521",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "While we selected a reduced model with an expected better prediction performance, for this test set, the RMSE of the full model is lower than that of the reduced one. Note that this is only one estimate of the true test RMSE based on a random data split. A different split may give a different result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2ddbd4345e66d08310af50359e425dad",
     "grade": false,
     "grade_id": "cell-09a83d9fd6da4516",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2 Dataset: Cars Selling Price\n",
    "\n",
    "In this section we will work with a different dataset that contains many categorical variables with multiple levels since not all selection algorithms can be used in those cases.\n",
    "\n",
    "The dataset [Vehicle dataset](https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho/data), from Kaggle contains 20 input variables on different characteristics of cars sold in India, that can be used to predict the cars' selling price, `Price.` We will select only some of these inputs in this example (see code below). \n",
    "\n",
    "Although the description of the dataset does not contain too much information about the variables (e.g., units), the names of most variables are self-explanatory and can be used to illustrate and address the problem. For example,\n",
    "\n",
    "- `FuelType`: a character vector with values 'Petrol', 'Diesel', 'CNG', 'CNG + CNG', 'LPG', 'Hybrid', 'Petrol + CNG', but only 'Petrol','Diesel', and 'CNG' has enough counts for an analysis\n",
    "\n",
    "> Note that even if this is not a factor variable, R will create 6 dummy variables to include a character vector into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4484d31615626eb248fc87f7721752c",
     "grade": false,
     "grade_id": "cell-44aabc04af56c7c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "cars_price <- \n",
    "    read_csv(\"data/cars_price.csv\") %>%\n",
    "    dplyr::select(-Make,-Model,-Location,-Color,-Engine,-MaxPower,-MaxTorque)%>%\n",
    "    subset(FuelType %in% c('Petrol','Diesel','CNG'))%>%\n",
    "    drop_na() \n",
    "\n",
    "unique(cars_price$FuelType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4964392c44df197920bde0881dfb47a",
     "grade": false,
     "grade_id": "cell-8c82f840ba3dbb27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1 Stepwise Selection with Categorical Variables\n",
    "\n",
    "As we learned in previous lectures, dummy variables are needed to include categorical covariates in statistical models. To represent a categorical variable with $q$ levels, we need $q-1$ dummy variables. \n",
    "\n",
    "The function `regsubsets()` evaluates the contribution of each of these dummy variables and may select only a subset of them for the final model. However, this selection depends on the reference level used, which in most cases, is randomly chosen. In  other words, in general, we are interested in the contribution of the *whole* categorical variable and not of individual levels of it relative to an arbitrary reference level. \n",
    "\n",
    "Statistically, we need to evaluate the joint contribution of all dummy variables from each categorical variable at once, instead of evaluating each dummy variable at a time. The function `stepAIC()` in the package `MASS` iteratively adds (`direction = \"forward\"`) and/or removes (`direction = \"backward\"`) predictors that decrease an information criterion (AIC or BIC).\n",
    "\n",
    "In the following problems you will illustrate the limitation of `regsubsets()` and use `stepAIC()` to select a model using stepwise algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd41e15a02177cb013dbf051751f4feb",
     "grade": false,
     "grade_id": "cell-0e77d4f41bd3a0d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll first split this dataset into a training and a test set using the tidymodels package.\n",
    "\n",
    "Run this code to split the dataset `cars_price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e013d1b572272642ab3ae86e39645937",
     "grade": false,
     "grade_id": "cell-92b7bf3d7b18b4a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#run this cell\n",
    "set.seed(301)\n",
    "\n",
    "cars_price_split <- \n",
    "    cars_price %>%\n",
    "    initial_split(prop = 0.5, strata = Price)\n",
    "\n",
    "training_cars <- training(cars_price_split)\n",
    "testing_cars <- testing(cars_price_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e18ec6f568c223f78962559294d3a167",
     "grade": false,
     "grade_id": "cell-c68da77ae4ac7863",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to see a few rows of the data\n",
    "\n",
    "head(training_cars, 3)\n",
    "cat('\\nTraining data has', nrow(training_cars), 'rows.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "def713e76bfabf69157e9f9723c89e73",
     "grade": false,
     "grade_id": "cell-d13aa6c7d2f1f3ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You don't want to even look at the test data. \n",
    "# Set it aside.\n",
    "\n",
    "cat('\\nTest data has', nrow(testing_cars), 'rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14636e0c17dca0908489f963dab5ce69",
     "grade": false,
     "grade_id": "cell-10467dee73f91bc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.0**\n",
    "<br>{points: 2}\n",
    "\n",
    "Write your own code to fit the following 2 linear models. You can use `tidymodels()` if you want. We'll test the estimated coefficients obtained in both cases.\n",
    "\n",
    "- Fit an intercept-only model using data from `training_cars` and `Price` as a response. Store the output in an object named `cars_null` and the estimated coefficients in an object called `cars_null_results`.\n",
    "  \n",
    "- Fit a MLR using data from `training_cars` and `Price` as a response. Store the output in an object named `cars_full` and the estimated coefficients in an object called `cars_full_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c87e7607c1ca74c38451c63bd8313930",
     "grade": false,
     "grade_id": "cell-54222a0598e1a15a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Your code goes here. \n",
    "\n",
    "#cars_null <- ...\n",
    "#cars_null_results <- ...\n",
    "\n",
    "#cars_full <- ...\n",
    "#cars_full_results <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68215e69121fe09c2dc2b54e893dd668",
     "grade": true,
     "grade_id": "cell-92bf691443e89d29",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.0.0()\n",
    "test_2.0.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71eff923360f327e3e34ffa93b8eafcc",
     "grade": false,
     "grade_id": "cell-4c9b76bcb395b3d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1.1 Stepwise selection using `regsubsets()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f39b1edd51adfa6222677d23030f1f0",
     "grade": false,
     "grade_id": "cell-b459366ee166c99d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "Let's use a **forward selection** algorithm to select a predictive model of the selling price of a car.\n",
    "\n",
    "Use `regsubsets()` with `training_cars` and call the resulting object `cars_forward_sel`. This object has to indicate  selected models for each model size, from **1 to 17 input variables** (specify it in the argument `nvmax`).\n",
    "\n",
    "The code below can be used to select the best nested models of each size.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a13891d183f89122d26fc5a32f3ba66",
     "grade": false,
     "grade_id": "cell-746e43f4f6c7046c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# cars_forward_sel <- ...(x = ... ~ ., nvmax = ...,\n",
    "#                                   data = training_cars,\n",
    "#                                   method = \"...\")\n",
    "\n",
    "# cars_forward_summary <- ...(cars_forward_sel)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "cars_forward_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "241b5fd9447409e54fd0ef2878016b00",
     "grade": true,
     "grade_id": "cell-5e5f9219000d635c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f689071e9ec8dab68e56f8e96d058d88",
     "grade": false,
     "grade_id": "cell-1372babbee624abd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "Create a tibble to store the performace measures of each model selected by `regsubsets`. Call the resulting table `cars_forward_performance`\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76f05e9f9c572ae01c47d44518fce1ef",
     "grade": false,
     "grade_id": "cell-42ff53554f9c110a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# cars_forward_performance <- tibble(\n",
    "#     n_input_variables = ...,\n",
    "#     RSQ = cars_forward_summary$...,\n",
    "#     RSS = ...,\n",
    "#     ADJ_R2 = ...,\n",
    "#     Cp = ...,\n",
    "#     BIC = ...,\n",
    "# )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "cars_forward_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "402d6f5f831762b1f320aef05615cf61",
     "grade": true,
     "grade_id": "cell-f07064383a152635",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52abdd85a5e05bd45a581814ebc20e66",
     "grade": false,
     "grade_id": "cell-bb225ded7d0d5caa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the code below to extract the name of the variables in the model with the lowest BIC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d86f0ca24ef4f1e1bb440f701ba803fb",
     "grade": false,
     "grade_id": "cell-bb66653ff105e5dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "\n",
    "bic_min = which.min(cars_forward_summary$bic) \n",
    "\n",
    "selected_var <- names(coef(cars_forward_sel, bic_min))[-1]\n",
    "selected_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a587dedd7b661c78eac9fad6131a1163",
     "grade": false,
     "grade_id": "cell-5aeafea3019d0490",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "When the BIC is used to select a predictive model, only 11 input variables are selected. Some of these variables correspond to dummy variables of categorical variables in the dataset. \n",
    "\n",
    "Examine the set of variables selected and explain the results of the selection process for the categorical variables.\n",
    "\n",
    "In particular, check if some dummy variables were selected. For those selected, check if all the set of dummy variables from the corresponding categorical variable were selected as well. \n",
    "\n",
    "- Taking one of these as an example, describe the which comparison was selected as important by the algorithm and which one was discarded. \n",
    "\n",
    "- Reflect and explain on the possible drawbacks of this proceedure and results in the context of an inference problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "jp-MarkdownHeadingCollapsed": true,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a64264722cb33172c62ff03a296b2bed",
     "grade": true,
     "grade_id": "cell-f805b89611f75c1f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "> *Your answer goes here.*\n",
    "\n",
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d502bd8697fce3d7d64de53218617294",
     "grade": false,
     "grade_id": "cell-2cfcf3ae7fbcf3c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.1.2 Stepwise selection using `stepAIC()`\n",
    "\n",
    "In this section we'll use a different function `stepAIC()` which evaluates all dummy variables from categorical variables together in the stepwise search.\n",
    "\n",
    "The function `stepAIC()` in the package `MASS` iteratively adds (`direction = \"forward\"`) and/or removes (`direction = \"backward\"`) predictors that decrease an information criterion (AIC or BIC). You can also set `direction = \"both\"` (default) to perform a forward-backward search that, at each step, decides whether to add or remove a predictor. \n",
    "\n",
    "For $n$ equal to the sample size, setting $k = log(n)$, the BIC is computed. If $k = 2$, the AIC is computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "13d4c94e9632e3baf700d474f858e037",
     "grade": false,
     "grade_id": "cell-e27067025b8b1988",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.4**\n",
    "<br>{points: 1}\n",
    "\n",
    "Use the function `stepAIC()` and `training_housing` to perform a \"backward\" search, starting from the full model (`cars_full`) and ending at the intercept-only model (`cars_null`) or until the BIC can not be further reduced. \n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe8373eab69835dda51847479d1ba5c4",
     "grade": false,
     "grade_id": "cell-c73a546f17165e4c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# n <- ...\n",
    "# modAIC_back <- stepAIC(..., direction = \"...\", k = log(n))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "summary(modAIC_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "536437a615aeac8fbbd61f59fefe0048",
     "grade": true,
     "grade_id": "cell-21ca0ba852fb9ef9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95d0baafb34e6a357128ed37a654928b",
     "grade": false,
     "grade_id": "cell-4543bc93f467b1b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<font style='color:darkred'>**Note that the `Df` column in the output of the search algorithm indicates the number of variables that were simultaneously added or removed by the algorithm!**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "051645bdc3c58093af5b7611212bc340",
     "grade": false,
     "grade_id": "cell-3fe11c2c9bc76f32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.5**\n",
    "<br>{points: 1}\n",
    "\n",
    "Describe the model selected using the search in *Question 2.4*. Is the model selected that same as that in *Question 2.1*? How do they difer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "709552fed600b7aef93fe0b7a244b4e3",
     "grade": true,
     "grade_id": "cell-09a19d1758661893",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "> *Your answer goes here.*\n",
    "\n",
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "31559aa93db69e447da59b35cacc8815",
     "grade": false,
     "grade_id": "cell-47a28a7204facaf4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.6**\n",
    "<br>{points: 1}\n",
    "\n",
    "In this question you will change the direction to start the search at the intercept-only model and add variables sequentially until the minimum BIC is obtained.\n",
    "\n",
    "> Note: the scope argument needs to indicate the model where the algorithm starts the  (`lower`) and the model where it ends (`upper`), otherwise, the algorithm will not do any search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29ed5d0e19e2d2de3d946d982188320d",
     "grade": false,
     "grade_id": "cell-0f12c26d67ba3810",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# modAIC_forward <- MASS::stepAIC(mod_null, direction = \"forward\",\n",
    "#               scope = list(lower = mod_null, upper = mod_full), k = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c16f9c4e0cb2b7c0f3c41231c7a04474",
     "grade": true,
     "grade_id": "cell-e43eac7916f20f53",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2efc6f3ba198d09db3a3e2871971acf3",
     "grade": false,
     "grade_id": "cell-cb79377c977501dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.7: True or False**\n",
    "<br>{points: 1}\n",
    "\n",
    "The backward and the forward algorithms selected the same model for this dataset.\n",
    "\n",
    "Are they the same?\n",
    "\n",
    "*Assign your answer to an object called answer2.7. Your answer should be either \"true\" or \"false\", surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "623bbcd56ed38b2c5297ff7e635e959b",
     "grade": false,
     "grade_id": "cell-14df58539fc6e3ea",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer2.7 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8a560da9a772eafef2877301a8619e9e",
     "grade": true,
     "grade_id": "cell-78438940f4db63a8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5470580a0e8a54ee62c0ff544cae5c8",
     "grade": false,
     "grade_id": "cell-4f4f6d5f34b4d97a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The function `summary()` gives the results of the fitted model on the same dataset that was used to select the variables. We will see later in the course that the inference results may not be valid if the same data is used to select and test.\n",
    "\n",
    "Run the code below to compare the results of the individual hypothesis tests when an independent dataset is used to test the model selected by the  algorithm going backwards. \n",
    "\n",
    "<font style='color:darkred'>**You can see that variables that were statistically significant when tested using the training set tend not be significant in the test set, even when both sets have the same size.**</font>\n",
    "\n",
    "We'll generalize this result later using a simulation study!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88847939386d42e40d48289438031768",
     "grade": false,
     "grade_id": "cell-e49f3e6721dd5af6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "pval_test <- tidy(lm(Price ~ Year + FuelType + Owner + Drivetrain + Length + \n",
    "    Width + Height + SeatingCapacity + FuelTankCapacity, data = testing_cars)) %>%\n",
    "            select(term, p.value) %>%\n",
    "            rename(p.value.test = p.value)\n",
    "\n",
    "pval_train <- tidy(lm(Price ~ Year + FuelType + Owner + Drivetrain + Length + \n",
    "    Width + Height + SeatingCapacity + FuelTankCapacity, data = training_cars)) %>%\n",
    "            select(term, p.value) %>%\n",
    "            rename(p.value.train = p.value)\n",
    "\n",
    "full_join(pval_train, pval_test, by = \"term\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
