{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6c325745ed5d8ed40a37781f2cbab1e0",
     "grade": false,
     "grade_id": "cell-a02bfa12010e4d4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Worksheet 2: A/B Testing and principled peeking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0de6e52f366103b8e5f7adcf0ba652a7",
     "grade": false,
     "grade_id": "cell-0d73a1ef28585e4f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Review from worksheet 1\n",
    "\n",
    "Some basic concepts to recall:\n",
    "\n",
    "### Sampling Distribution\n",
    "\n",
    "- The *sampling distribution* is the distribution of a statistic (e.g., sample mean, sample proportion, t-statistic, z-score).\n",
    "    - The sampling distribution is *different from* the sample distribution\n",
    "    - The sampling distribution is *different from* the population distribution\n",
    "        \n",
    "- We need a sampling distribution to make probabilistic statements about our statistic.\n",
    "    - For example: if the population mean is actually 0 (we usually want to test this, you don't know it), what is the probability that the sample mean would be greater than 1?\n",
    "    \n",
    "- The problem is that the sampling distribution is usually unknown, mainly because the population distribution is unknown.\n",
    "    \n",
    "- You may be able to derive mathematically the sampling distribution if you know the population distribution (rarely in practice).\n",
    "    - For example, if your sample comes from Normal distribution, then the sample mean is Normal as well \n",
    "\n",
    "- In certain cases, you can use results of the CLT if your sample size is large and additional assumptions are met.\n",
    "    - For exmple, for a sample of independent and identically distributed random variables, if the sample size is large, the sampling distribution of the mean is approximately Normal\n",
    "    \n",
    "- You can use bootstrapping (although conditions exist as well) to approximate the sampling distribution.\n",
    "\n",
    "### Errors in Hypothesis Tests\n",
    "\n",
    "There are 2 types of errors in a hypothesis testing problem: \n",
    "\n",
    "- **Type I error**: rejecting $H_0$ when $H_0$ is true\n",
    "\n",
    "- **Type II error**: failing to reject $H_0$ when $H_0$ is false\n",
    "\n",
    "The probability of the type I error is usually called **significance level** (aka $\\alpha$) and it is set by the analyst when designing a test.\n",
    "\n",
    "Another important measure used to design a test is the **power**:\n",
    "\n",
    "- **Power**: the probability of rejecting $H_0$ when $H_0$ is false (i.e., power = $1 - P(\\text{type II error})$)\n",
    "\n",
    "### $p$-value\n",
    "\n",
    "The $p$-value can be used to assess the significance of the observed results by comparing its value to the specified significance level:\n",
    "   - Is $p < \\alpha$?? \n",
    "\n",
    "But what is a $p$-value?? It's been greatly missused for sure!!\n",
    "\n",
    "- **$p$-value**: the probability, under the model specified in $H_0$, that a statistic would be at least as extreme as its observed value \n",
    "\n",
    "Note that the $p$-value is **NOT**:\n",
    "\n",
    "- the probability that $H_0$ is true \n",
    "- the probability that $H_0$ is false\n",
    "- the probability that the statistic observed was produced by random chance alone\n",
    "- a measure of the importance of the observed effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cfeeef9952eb81fc5753b518ae1819f8",
     "grade": false,
     "grade_id": "cell-5bf3eac0664df934",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Learning Objectives \n",
    "\n",
    "After completing this week's worksheet and tutorial work, you will be able to:\n",
    "\n",
    "1. Discuss why the methods learned in past courses are not sufficient to answer the more complex research problems being posed in this course (in particular stopping an A/B test early).\n",
    "2. Explain sequential testing and principled peeking and how it can be used for early stopping of an experiment (e.g., A/B testing).\n",
    "3. Write a computer script to perform A/B testing optimization with and without using principled peeking.\n",
    "4. Discuss the tradeoff between stopping earlier and certainty of significance, and thereal world implications (e.g., what does the FDA require for early stopping of clinical trials versus Facebook ads optimization?).\n",
    "5. List other questions related to A/B testing optimization that may be relevant in a real data application (e.g., what features cause a Facebook ad to perform best?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61a7d8be3a5ee43163f24092c2b693a0",
     "grade": false,
     "grade_id": "cell-aeb5ce9a4b99cc68",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4092861800a8c0ac79088f9f4bd7d047",
     "grade": false,
     "grade_id": "cell-e27b96fe9888ea42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell before continuing.\n",
    "library(tidyverse)\n",
    "library(infer)\n",
    "library(broom)\n",
    "install.packages(\"gsDesign\")\n",
    "library(gsDesign)\n",
    "\n",
    "source(\"tests_worksheet_02.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b2c7729ee2813bd0fd8f7abccb697ee",
     "grade": false,
     "grade_id": "cell-c1081d96a47b5814",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part I (Tuesday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bc9d855f89581d74bbb92df7c434145",
     "grade": false,
     "grade_id": "cell-3a017e5bee55fcfd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. A/B Testing Optimization\n",
    "\n",
    "### 1.1 A/B testing\n",
    "\n",
    "**A/B testing** refers to an experiment, in which users are randomly assigned to one of two variations of a product or service: control (A) and variation (B) to see if variation B should be used for improvement.\n",
    "\n",
    "- A/B testing became very popular in the context of updating and improving websites. However, they can be used in many other contexts to monitor and update products and/or services.\n",
    "\n",
    "### Case study: Obama's 60 million dollar experiment\n",
    "\n",
    "In 2008, Obama's campaign was looking to increase the total amount of donations to the campaign. In December of 2007, they run an experiment to compare how different versions of the website can yield different responses of their visitors.\n",
    "\n",
    "In the original experiment they compared 24 different combinations of buttons and media. Visitors were randomly assigned to one of these variations and they track different response variables (i.e, conversion rate, amount donated, etc.)\n",
    "\n",
    "**The original website**\n",
    "\n",
    "![img](https://www.optimizely.com/contentassets/30f67b662917481e867d7c6b602d05d6/obama_homepage_original-445x313.png?width=785&mode=crop)\n",
    "\n",
    "**The winner website**\n",
    "\n",
    "![img](https://www.optimizely.com/contentassets/30f67b662917481e867d7c6b602d05d6/obama_winner-373x335.png?width=785&mode=crop)\n",
    "\n",
    "> \"This experiment taught us that every visitor to our website was an opportunity and that taking advantage of that opportunity through **website optimization and A/B testing** could help us raise tens of millions of dollars.\" [Dan Siroker](https://www.optimizely.com/insights/blog/how-obama-raised-60-million-by-running-a-simple-experiment/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9399b78879c9aa79f014ebb97469275d",
     "grade": false,
     "grade_id": "cell-2bde0738e276694f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Experimental Design\n",
    "\n",
    "In any statistical analysis there are some important steps to define:\n",
    "\n",
    "- post the *question(s)* you want to answer using data\n",
    "\n",
    "- *design* the experiment to address your question(s)\n",
    "\n",
    "    - an **important quantity** defined in the design of the experiment is the **sample size**, which ideally is calculated based on a power analysis\n",
    "\n",
    "    - identify appropriate methodologies to analyze the data. For example, you may prefer a test statistic that can control Type I error with high power (many of the statistics you've learned have this property!)\n",
    "\n",
    "- run the experiment to collect data \n",
    "\n",
    "- analyze the data according to the experimental design and make decisions\n",
    "\n",
    "    - for example, if the $p$-value of the test is smaller than the specified significance level, reject the null hypothesis\n",
    "\n",
    "**Note**: This process is usually non-linear and may take multiple iterations among some of these steps, nicely described as \"epicycles\" by R. Peng and E. Matsui in [\"The Art of Data Science\"](https://bookdown.org/rdpeng/artofdatascience/images/epicycle.png)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c1bb85359edc187a89b053fa5c4ba3a9",
     "grade": false,
     "grade_id": "cell-6cee65fd8f6124c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "An important question that motivated Obama's website experiment was if a variation of the current website could yield higher donations from its visitors. \n",
    "\n",
    "A key factor of the experimental design is deciding which statistical tool will be used to analyzed the data collected. Given that they do not have previous information about the population distribution, they decided to use a classical $t$-statistic to compare differences of means.\n",
    "\n",
    "Another important planned quantity is the significance level of the test, a.k.a **Type I error rate**, which is:\n",
    "\n",
    "\n",
    "**A.** the probability of finding a significant difference in donation sizes between the two variations, if the new website indeed attracts, on average, larger donations.\n",
    "\n",
    "**B.** the probability of *not* finding a significant difference in donation sizes between the two variations, if the new website indeed attracts, on average, larger donations.\n",
    "\n",
    "**C.** the probability of finding a significant difference in donation sizes between the two variations, if the mean of the size of the donations of both websites are equal.\n",
    "\n",
    "**D.** the probability that the new website indeed attracts larger donations.\n",
    "\n",
    "*Assign your answer to an object called `answer1.2.0`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2a43d7b3461b44cbee055ed6f05a57a",
     "grade": false,
     "grade_id": "cell-1995b40417991d4a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.2.0 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f249c3cde588ec2cb2fa2c6ba2003bc0",
     "grade": true,
     "grade_id": "cell-6dd3efdd0b5f8be8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.2.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "441dc0d93f5d87167c4a32ab4ea818df",
     "grade": false,
     "grade_id": "cell-fde3bc40bf7b213a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "The designers of the experiment also need to decide how large the experiment will be since there are large costs (including opportunity costs) related to the experiment. \n",
    "\n",
    "Thus, for the statistical test planned, they decide to conduct a **power analysis** to:\n",
    "\n",
    "**A.** estimate the minimum sample size required, given a desired significance level, expected difference in mean donations, and statistical power.\n",
    "\n",
    "**B.** maximize the probability of finding a significant difference in donation sizes between the two variations, if the new website indeed attracts larger donations.\n",
    "\n",
    "**C.** minimize the probability of not finding a significant difference in donation sizes between the two variations, if the new website indeed attracts larger donations.\n",
    "\n",
    "\n",
    "*Assign your answer to an object called `answer1.2.1`. Your answer should be one of `\"A\"`, `\"B\"`, or `\"C\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "efb43872ac58ef5f2730d0d786998495",
     "grade": false,
     "grade_id": "cell-9f84185e30e2353a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.2.1 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fd05c11fe78beabeeb37643f2798b20",
     "grade": true,
     "grade_id": "cell-1bf75eb9cdbe85fb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "21fc408942c2df132a2a6476cb047e2d",
     "grade": false,
     "grade_id": "cell-f3908eb5114147b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "After deciding on the sample size required and *randomly* assigning visitors to each variation of the website, the company will start analyzing the size of the donations made by visitors. \n",
    "\n",
    "Since the sample size planned is large enough, the analysts will conduct a classical hypothesis test and compute $p$-values and confidence intervals based on results from the CLT.\n",
    "\n",
    "Considering the opportunity costs involved in this experiment, the analysts are going to monitor the size of the donations closely and stop the experiment earlier if they find (using a standard 2-samples $t$-test) that the new website attracts higher donations. \n",
    "\n",
    "**However, computing (raw) $p$-values before collecting *all* the full can seriously bias the results of the experiment. True or False??**\n",
    "\n",
    "**Note**: \"raw\" here means the $p$-values calculated with a $t$ sampling distribution based on results derived from the CLT. \n",
    "\n",
    "*Assign your answer to an object called answer1.2.2. Your answer should be either \"true\" or \"false\", surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c97dde4f8af67e3b520aec381a4057af",
     "grade": false,
     "grade_id": "cell-26a62021df5e0239",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer1.2.2 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdbb162adba06025fce4f866fae53eea",
     "grade": true,
     "grade_id": "cell-d74e84bf990ca0e4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_1.2.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "308d636924f21911785423a5983f5559",
     "grade": false,
     "grade_id": "cell-0e6dc2486456debb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Early Stopping in A/B Testing\n",
    "\n",
    "> ***In classical hypothesis testing theory, the sample size must be fixed in advance when the experiment is designed!!***\n",
    "\n",
    "### 2.1 Dashboards to monitor A/B testing\n",
    "\n",
    "In the last decade, many A/B testing platforms have been developed to assist companies to analyze, report and visualize the results of their experiments. Some notable examples include:\n",
    "\n",
    "   - Optimizely\n",
    "   \n",
    "   - Google Analytics\n",
    "   \n",
    "   - Crazy Egg\n",
    "   \n",
    "These platforms allow the users to *continuously monitor* the $p$-values and confidence intervals in order to re-adjust their experiment dynamically. But,\n",
    "\n",
    "> ***Is it ok to peek at results before all the data are collected??***\n",
    "\n",
    "![img](https://miro.medium.com/max/1400/1*W8mUB5A96ufsbMWLqScVOA.png)\n",
    "<font color=grey>Figure by D. Meisner in Towards Data Science </font>\n",
    "\n",
    "\n",
    "### 2.2 Early stopping\n",
    "\n",
    "**Early stopping** refers to ending the experiment earlier than originally designed.\n",
    "\n",
    "> ***Can we stop or re-design the experiment earlier if we have supporting evidence to do so??***\n",
    "\n",
    "- a company would like to stop an experiment that results is losses in revenue\n",
    "\n",
    "- a medical treatment may want to switch as early as possible to a more effective drug\n",
    "\n",
    "\n",
    "#### Let's use data to answer to this question!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07b231f0bd37d43f519a401dd6b4ed70",
     "grade": false,
     "grade_id": "cell-fcba136051353030",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.3 A/A testing\n",
    "\n",
    "To examine the problem of early stopping, let's simulate data for which $H_0$ is true (i.e., there is no effect)\n",
    "  - we can think of a scenario where both groups are equal (aka A/A testing)\n",
    "  \n",
    "  - in this scenario, we know that claiming a significant result is a false discovery\n",
    "  \n",
    "**Note**: although this seems artificial, it is a widely used technique to test experiments and platforms\n",
    "\n",
    "To compute error rates, we will generate 100 of such experiments:\n",
    "\n",
    "![img](img/aa-Obama.png)\n",
    "<font color=grey>Figure by [R. Lourenzutti](https://lourenzutti.github.io/tutorials/ab-testing/ab-test.html) </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40c77492b7acc8b62adfb3af8dcf55ac",
     "grade": false,
     "grade_id": "cell-bbb063d5681a5acb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Experimental design\n",
    "\n",
    "The campaign organizers have decided to:\n",
    "\n",
    "- run a balanced experiment with a *pre-set* sample size of 1000 visitors per variation (total sample size of 2000) \n",
    "\n",
    "- **sequentially collect** the data in batches of 50 visitors per group\n",
    "\n",
    "- **sequentially analyze** the data using two-sample $t$-tests\n",
    "\n",
    "- **sequentially compute and monitor** (raw) $p$-values \n",
    "\n",
    "- **stop** the experiment **once a significant result** is found \n",
    "\n",
    "Run this experiment 100 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c620783223935529894867057e94a989",
     "grade": false,
     "grade_id": "cell-c75f59a0dcf09528",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Simulation function\n",
    "\n",
    "We have prepared a function for you that: \n",
    "\n",
    "- generates two samples, each of size `n`, from two (known) Normal distribution, the control and the variation\n",
    "  - note that this can only be done in a simulation study. In a real data analysis we collect data from an *unknown* distribution\n",
    "\n",
    "- analyzes the data in an incremental way by `sample_increase_step` until all `n` samples in each treatment group are analyzed \n",
    "  - for example: compares donations by batches of visitors of each website variation until data from all planned visitors are collected \n",
    "\n",
    "- returns the $t$-statistic and $p$-value (computed by a two-sample $t$-test) for every set of collected data\n",
    "  - for example: $p$-values to assess the difference in means of the size of donations made by visitors of each website as batches of data are collected\n",
    "\n",
    "For example, if `sample_increase_step` is 20, and `n=500`, the function will:\n",
    "1. draw samples of 500 experimental units from the control distribution and 500 from the variation distribution;\n",
    "1. subset the first 20 experimental units from each sample;\n",
    "2. perform the two-sample $t$-test and return the associated $t$-statistic and $p$-value;\n",
    "3. add 20 more experimental units to each group \n",
    "4. perform the two-sample $t$-test (now based on 40 experimental units per group) and return the associated $t$-statistic and $p$-value  \n",
    "5. add another 20 experimental units to each group \n",
    "6. perform the two-sample $t$-test (now based on 60 experimental units per group) and return the associated $t$-statistic and $p$-value \n",
    "$$\n",
    "\\vdots\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\n",
    "$$\n",
    "and so on, until the total sample size in each group is 500 (as originally planned).\n",
    "\n",
    "The function returns a tibble that has two columns:\n",
    "\n",
    "- `inc_sample_size`: the sample size of the set of data analyzed \n",
    "- `statistic`: $t$-statistic calculated by the `t.test()` function\n",
    "- `p_value`: $p$-value calculated by the `t.test()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b871c7f7dd47cb2541673f69fe527541",
     "grade": false,
     "grade_id": "cell-a1fc35871231916c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Two-sample t-test with tracking sequential statistic and p-values by incremental sample sizes until getting to n.\n",
    "\n",
    "# @param n (numeric): Initially planned sample size for each group (for simplicity, n needs to be a multiple of sample_increase_step).\n",
    "# @param d_0 (numeric): effect size.\n",
    "# @param mean_current (numeric): Population mean for control variation.\n",
    "# @param sd_current (numeric): Population standard deviation for current variation.\n",
    "# @param sd_new (numeric): Population standard deviation for new variation.\n",
    "# @param sample_increase_step (numeric): Sample size increment.\n",
    "\n",
    "# @return p.value.df: A tibble that has 3 columns:\n",
    "# inc_sample_size, statistic, and p_value \n",
    "\n",
    "incremental_t_test <- function(n, d_0, mean_current, sd_current, sd_new, sample_increase_step) {\n",
    "  sample_current <- rnorm(n, mean = mean_current, sd = sd_current)\n",
    "  sample_new <- rnorm(n, mean = mean_current + d_0, sd = sd_new)\n",
    "\n",
    "  p.value.df <- tibble(\n",
    "    inc_sample_size = rep(0, n / sample_increase_step),\n",
    "    statistic = rep(0, n / sample_increase_step),\n",
    "    p_value = rep(0, n / sample_increase_step)\n",
    "  )\n",
    "\n",
    "  current_sample_size <- sample_increase_step\n",
    "  \n",
    "  for (i in 1:nrow(p.value.df))\n",
    "  {\n",
    "    t_test_results <- t.test(sample_new[1:current_sample_size], sample_current[1:current_sample_size],\n",
    "      var.equal = TRUE,\n",
    "      alternative = \"greater\"                      \n",
    "    )\n",
    "    p.value.df[i, \"statistic\"] <- as_tibble(t_test_results$statistic)\n",
    "    p.value.df[i, \"p_value\"] <- as_tibble(t_test_results$p.value)\n",
    "    p.value.df[i, \"inc_sample_size\"] <- current_sample_size\n",
    "    current_sample_size <- current_sample_size + sample_increase_step\n",
    "  }\n",
    "\n",
    "  return(p.value.df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ed88bd99ca7b0a1e006f3c1c31d097a",
     "grade": false,
     "grade_id": "cell-665284db692677cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "In a simulation study, we know the true population distributions! furthermore, in an A/A testing, we know that there is no true difference between the population means.\n",
    "\n",
    "The function used to simulate the data assumes:\n",
    "\n",
    "**A.** the sample distributions are $\\mathcal{N}(0,1)$\n",
    "\n",
    "**B.** the population distribution of the donation sizes of visitors of the current website is $\\mathcal{N}(\\mu_0,\\sigma_0^2)$, where $\\mu_0$ = mean_current and $\\sigma_0$ = sd_current\n",
    "\n",
    "**C.** the sample distribution of the donation sizes of visitors of the current website is $\\mathcal{N}(\\mu_0,\\sigma_0^2)$, where $\\mu_0$ = mean_current and $\\sigma_0$ = sd_current\n",
    "\n",
    "*Assign your answer to an object called `answer2.3.0`. Your answer should be one of `\"A\"`, `\"B\"`, or `\"C\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b44250af0fe3a5a72ee38e6132012297",
     "grade": false,
     "grade_id": "cell-559e3a0d7e979412",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer2.3.0 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76bb891edc92909ecc85bfb38e6dee23",
     "grade": true,
     "grade_id": "cell-ff35930d17aa5189",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.3.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bea3efd982f74e74d8758af9b35cc546",
     "grade": false,
     "grade_id": "cell-b13993a85177eb2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "In Obama's campaign example, we simulate data that reflects no difference in the expected size of the donations (since all visitors are exposed to the same website) \n",
    "\n",
    "Then, suppose that the compaign organizers want to analyze the data in batches of 50 visitors per group until a total of $n = 1000$ visitors have watched each website.\n",
    "\n",
    "Use the `incremental_t_test` function to conduct the company's experiment. \n",
    "\n",
    "*Save the result in an object called `answer2.3.1`. Your answer should be a tibble with two columns: `inc_sample_size`, and `p_value`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce278e7cf44617eb93040d70fc4d7d19",
     "grade": false,
     "grade_id": "cell-d35500ae42606372",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(301) # do not change this.\n",
    "\n",
    "#answer2.3.1 <- \n",
    "#    incremental_t_test(n = ..., d_0 = ..., sample_increase_step = ..., mean_current = 200, sd_current = 50, sd_new = 50)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "answer2.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07e735af97885266c97bff1ce2432336",
     "grade": true,
     "grade_id": "cell-10bc0e2c6b493c38",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.3.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fae47a7020ff58c69a0f4e35dd68ac71",
     "grade": false,
     "grade_id": "cell-9048254aa38b5ce0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "Using the data stored in `answer2.3.1`, plot the $p$-value sequence as a **line** with the incremental sample size on the $x$-axis and $p$-value on the $y$-axis. Add a dashed horizontal red line that indicates a threshold of the significance level $\\alpha = 0.05$. The `ggplot()` object's name will be `sequential_pvalue`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6252859acf2db6ef0d7973fb6ad57a94",
     "grade": false,
     "grade_id": "cell-fc5c07b5db1c2072",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 9) # Adjust these numbers so the plot looks good in your desktop.\n",
    "\n",
    "# sequential_pvalue <- \n",
    "#   answer2.3.1 %>%\n",
    "#   ggplot() +\n",
    "#   geom_line(aes(x = ..., y = ...)) +\n",
    "#   theme(\n",
    "#     text = element_text(size = 18),\n",
    "#     plot.title = element_text(face = \"bold\"),\n",
    "#     axis.title = element_text(face = \"bold\")\n",
    "#   ) +\n",
    "#   geom_point(aes(x = ..., y = ...)) +\n",
    "#   ggtitle(\"Evolution of p-values in Experiment 1\") +\n",
    "#   ylab(\"p-value\") +\n",
    "#   xlab(\"Sample Size\") +\n",
    "#   geom_hline(\n",
    "#     yintercept = ...,\n",
    "#     colour = \"red\",\n",
    "#     linetype = \"twodash\"\n",
    "#   ) +\n",
    "#   coord_cartesian(ylim = c(0, 1)) +\n",
    "#   scale_y_continuous(breaks = seq(0, 1, by = 0.05))\n",
    "\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "sequential_pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e4ca39c5305c818dbdfe016b53435e8",
     "grade": true,
     "grade_id": "cell-40525ca9d0396d4c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.3.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb19a2ea2bff0ab073cb2cd51348e169",
     "grade": false,
     "grade_id": "cell-d4f7748de806529f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "As mentioned in the **Experimental Design** section, the campaign organizers want to implement an early stopping (before reaching the maximum sample size of `n = 1000` visitors per website) to save time and resources allocated for the experiment.\n",
    "\n",
    "> Using a significance level $\\alpha = 0.05$, they would stop the experiment as soon as they find a significant result. \n",
    "\n",
    "Given the results in **Question 2.3.2**, the compaign organizers would stop the experiment \n",
    "\n",
    "**A.** once they finish collecting and analyzing all the data\n",
    "\n",
    "**B.** after 100 visitors have entered each website since the $p$-value is below the specified significance level\n",
    "\n",
    "**C.** after 150 visitors have entered each website since results are getting worse after that point\n",
    "\n",
    "*Assign your answer to an object called `answer2.3.3`. Your answer should be one of `\"A\"`, `\"B\"`, or `\"C\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8877f93256e65ec3c351cad165d0f658",
     "grade": false,
     "grade_id": "cell-e1144dfce0fb0091",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer2.3.3 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "774668bc2f568abd89a9238ba0fc8961",
     "grade": true,
     "grade_id": "cell-78a961a44fb63cee",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.3.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb5132da83f3436f099346783c84ecfc",
     "grade": false,
     "grade_id": "cell-120d8b0bb182bdc3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3.4**\n",
    "<br>{points: 1}\n",
    "\n",
    "Since the simulated data correspond to a **A/A testing** design, what error, if any, are the compaign organizers making by stopping the experiment as noted in **Question 2.3.3**?\n",
    "\n",
    "**A.** No error.\n",
    "\n",
    "**B.** Type I Error.\n",
    "\n",
    "**C.** Type II Error.\n",
    "\n",
    "*Assign your answer to an object called `answer2.3.4`. Your answer should be one of `\"A\"`, `\"B\"`, or `\"C\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "588d5f2f5c7499a6af980f25a539db4c",
     "grade": false,
     "grade_id": "cell-73ae270a2acc9896",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer2.3.4 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0caae53db30e427cd3a54c1caeef4a0",
     "grade": true,
     "grade_id": "cell-b8669caaf5a8c2a5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.3.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f58a105d84d958373b516d4bae0d36dd",
     "grade": false,
     "grade_id": "cell-74eb8ff6f774a3d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3.5**\n",
    "<br>{points: 1}\n",
    "\n",
    "The hypothesis test was designed with a $5\\%$ probability of falsely rejecting $H_0$ \n",
    "  - in the Obama's experiment, a false rejection means implies that the variation website attracts better donation when there's no real difference between the two population means. \n",
    "  \n",
    "So we can think that the possibility of making a mistake was always in the original plan. However, the strategy of stopping earlier may increase the (overall, family wise) probability of wrongly rejecting $H_0$. \n",
    "\n",
    "To examine this potential problem, the campaign organizers decided to: \n",
    "\n",
    "- perform the **A/A testing** experiment 100 times \n",
    "\n",
    "- count how many times they would wrongly reject $H_0$ with their strategy, and\n",
    "\n",
    "- compare it with the expected number of rejections given the significance level $\\alpha = 0.05$\n",
    "\n",
    "We wrote a code to perform the first step. Read it and learn from it!! Then, you need to work on the rest!\n",
    "\n",
    "Your answer will be a tibble with two columns: `n_rejections` and `expected_n_rejections`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ba985f160d883148e120b533cd3a4c4",
     "grade": false,
     "grade_id": "cell-16df4d1d8d3d08e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "set.seed(120)\n",
    "\n",
    "### Run this before continuing\n",
    "multiple_times_sequential_tests <- \n",
    "    tibble(experiment = 1:100) %>% \n",
    "    mutate(seq_test = map(.x = experiment, \n",
    "                          .f = function(x) incremental_t_test(n = 1000, d_0 = 0, sample_increase_step = 50, \n",
    "                              mean_current = 200, sd_current = 50, sd_new = 50)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6681ab29a8c011d32a6122d111acac0f",
     "grade": false,
     "grade_id": "cell-42e304128c6172ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.3.5 <- multiple_times_sequential_tests %>% \n",
    "#    mutate(reject = map_dbl(.x = seq_test, .f = function(x) sum(x$p_value< ...) > 0)) %>% \n",
    "#    summarise(n_rejections = ...(reject),\n",
    "#              expected_n_rejections = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "                            \n",
    "answer2.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e1e9b66fa698e276cca2a399ba5cef6",
     "grade": true,
     "grade_id": "cell-d1cd640149ad9173",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.3.5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e348b322c64267f5c96da49f68a41767",
     "grade": false,
     "grade_id": "cell-975e8ae738046922",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3.6**\n",
    "<br>{points: 1}\n",
    "\n",
    "Select the right option to complete the sentence below:\n",
    "\n",
    "> *With the strategy used by the company, the probability of Type I error is approximately ... the specified one.* \n",
    "\n",
    "**A.** equal to\n",
    "\n",
    "**B.** 3 times lower than\n",
    "\n",
    "**C.** 5 times lower than\n",
    "\n",
    "**D.** 3 times higher than\n",
    "\n",
    "**E.** 5 times higher than\n",
    "\n",
    "*Assign your answer to an object called `answer2.3.6`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, `\"D\"`,  or `\"E\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3609778d2ca6593699ea0d69b6a7f97",
     "grade": false,
     "grade_id": "cell-79c91d3bee9b8207",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer2.3.6 <- \"\"\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "564fdcc458c8ce28cafd6cfe665dc969",
     "grade": true,
     "grade_id": "cell-cbd492b554a7a745",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.3.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6e51d7b6fa5e164b1934b8761084ee7",
     "grade": false,
     "grade_id": "cell-8571d0cc926c0cf8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note**: not only the type I error rate is affected by this problem, but also the estimates themselves! If we analyze samples until the means of both groups are significantly far apart, we would also overestimate the effect size (difference between means)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0663d2d103059fc096d90f4bc2acb6b4",
     "grade": false,
     "grade_id": "cell-79540772deb2318e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### <font color=blue> In *classical hypothesis testing*, monitoring results in a dashboard and *stopping experiments earlier* than planned will increase the probability of *incorrectly* rejecting the null hypothesis (i.e., when there is no real effect). </font>\n",
    "\n",
    "   - the test was planned and designed for a *specific sample size*. If you conduct the analysis once *all* the data is collected, then the probability to falsely rejecting $H_0$ is the selected level of significance. \n",
    "    \n",
    "   - *but*, if instead you check the results $k$ times as you collect data, you have $k$ opportunities to *falsely reject* $H_0$. The probability of a type I error is larger than the set value specified when the experiment was designed!!\n",
    "\n",
    "![img](img/aa-Obama-pval100.png)\n",
    "<font color=grey>Figure by [R. Lourenzutti](https://lourenzutti.github.io/tutorials/ab-testing/ab-test.html) </font>\n",
    "\n",
    "**Interesting note**:\n",
    "> It can be proved, mathematically, that under the null hypothesis, the classical $p$-value will *always* cross $\\alpha$ if the experimenter waits long enough$^{*}$. This means that with increasing data, the probability of falsely rejecting a true $H_0$ approaches to 1!\n",
    "\n",
    "[*] David Siegmund. 1985. Sequential analysis: tests and confidence intervals.\n",
    "Springer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbaef286d993716be36d9bf243825503",
     "grade": false,
     "grade_id": "cell-ed7ca88cfe3e3e04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Part II (Thursday)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72e46bc59ff47bd6250821788de97a09",
     "grade": false,
     "grade_id": "cell-d650bbcceaf44efc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Review from last class\n",
    "\n",
    "Last class we learned that:\n",
    "\n",
    "- One may be tempted to peek at results of A/B tests as data are being collected\n",
    "\n",
    "- Stopping an experiment and rejecting $H_0$ as soon as the $p$-value is below the specified significance level can drastically inflate the type I error\n",
    "\n",
    "- Controlling the risk of wrongly rejecting the null hypothesis is not an easy task in A/B testing if peeking and early stops are allowed\n",
    "\n",
    "## Today:\n",
    "\n",
    "> How does experimentation platforms, like Optimizely, address this challenge?? \n",
    "\n",
    "- Users need to adaptively determine the sample size of the experiments since there are large opportunity costs associated with longer experiments. \n",
    "\n",
    "- When done correctly, stopping an experiment earlier (or re-designing it) can be beneficial in many contexts. \n",
    "\n",
    "- Users *are* monitoring results as they collect and analyze data and are making decisions accordingly.\n",
    "\n",
    "> How can we allow a user to stop when they wish, while still controlling the probability of falsely rejecting $H_0$ at the pre-specified level Î±?\n",
    "\n",
    "*Hint*: an **appropriate measure of \"enough evidence\"** is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a299628c2cd80589c0143f62763bde3",
     "grade": false,
     "grade_id": "cell-d34b54f2891270b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. Sequential testing \n",
    "\n",
    "**Sequential tests** are decision rules that allows users to test data sequentially as data come in. The experiment may be stopped earlier, meaning the sample size is dynamic, rather than fixed. \n",
    "\n",
    "> Sequential testing is just another flavour of a multiple comparison problem. If you make lots of comparisons, but donât correct for it, your error rates are inflated!!\n",
    "\n",
    "\n",
    "Many methods have been proposed to address the characteristics of the **A/B testing experimental designs**:  \n",
    "\n",
    "- For example, one way to control the type I error rate inflation in multiple testing problems is to adjust the p-value (e.g., Bonferroni, BH). \n",
    "\n",
    "- Some new methods propose using a different tests statistics and computing $p$-values differently\n",
    "    - In the *Optimizely platform*, a mixture sequential probability ratio test (mSPRT) tests are performed and *always valid* $p$-values are constructed to allow users to trade off between power and sample size dynamically while controlling the false rejection probability at the level $\\alpha$. \n",
    "\n",
    "\n",
    "There are different classes of sequential approaches: \n",
    "\n",
    "- **Group sequential designs**: the analyst pre-specifies when to inspect the data (interim analysis) and performs each analysis as a fixed sample one. The significance level of each interim analysis is set at some level that controls the Type I error, no matter when the user chooses to stop the test.\n",
    "\n",
    "- **Full sequential designs**: the analyst performs an analysis after every new observation, sequentially, in a principled way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "87cf5875bf6a72594041db1936bd8745",
     "grade": false,
     "grade_id": "cell-bf767b35df5480d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.1 Bonferroni\n",
    "\n",
    "In the next few exercises, you are going to investigate if a Bonferroni correction controls the type I error rate in A/B testing.\n",
    "\n",
    "We will use again the **A/A experimental design** of Obama's campaign since in that scenario we know that the (true) expected difference in donation sizes is zero (i.e., effect size = 0)\n",
    "\n",
    "**Recall**:\n",
    "Bonferroni's method can be thought as: \n",
    "\n",
    "- an adjustment of the $p$-values by multiplying them by the number of comparisons and keeping the significance level at a desired threshold, or \n",
    "\n",
    "- an adjustment of the significance threshold $\\alpha$ by dividing it by the number of comparisons, or\n",
    "\n",
    "- an adjustment of the critical value, computed with a sampling distribution, corresponding to the adjusted significance threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2b08056c5c1224be9d6ea52648d1c20b",
     "grade": false,
     "grade_id": "cell-a9faf86e9df5475b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.1.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "Since Obama's campaign organizers have decided to monitor the data every 50 visitors per website, they will perform 20 sequential tests. \n",
    "\n",
    "Suppose that after each interim analysis, they will use a Bonferroni correction to control the type I error rate at $5\\%$. Thus, using a classical two-sample $t$ test, they we will **reject $H_0$** if the raw $p$-value is: \n",
    "\n",
    "**A.** smaller than 0.05\n",
    "\n",
    "**B.** smaller than 0.0025 (adjusted threshold)\n",
    "\n",
    "**C.** greater than a 0.0025 (adjusted threshold)\n",
    "\n",
    "**D.** greater than 0.05 when multiplied by 4\n",
    "\n",
    "\n",
    "*Assign your answer to an object called `answer3.1.0`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"`, surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "861c671cdc2140c595e3c326295ca9bb",
     "grade": false,
     "grade_id": "cell-3cb122e7e6d294f2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer3.1.0 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa99edfbd813b80f79880daa4cebc194",
     "grade": true,
     "grade_id": "cell-bd42f162ef58b0c1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.1.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "729ad1207381991da47f3aa7d7fd1a64",
     "grade": false,
     "grade_id": "cell-e7d7b809d09fe3b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.1.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "Continuing with the problem stated in **Question 3.1.0**, the campaign organizers can also **reject $H_0$** if the observed $t$-statistic is:\n",
    "\n",
    "**A.** greater than `qt(1 - 0.05,998) = 1.65` \n",
    "\n",
    "**B.** greater than `qt(1 - 0.025,998) = 1.96`\n",
    "\n",
    "**C.** greater than `qt(1 - 0.0025,998) = 2.81` \n",
    "\n",
    "**D.** greater than 0.05\n",
    "\n",
    "\n",
    "*Assign your answer to an object called `answer3.1.1`. Your answer should be one of `\"A\"`, `\"B\"`, `\"C\"`, or `\"D\"`, surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "426e5657cb434697ede185dfb760a568",
     "grade": false,
     "grade_id": "cell-6f51027c4750089d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer3.1.1 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66eeb71b5ca6778f87f001281c6cdd04",
     "grade": true,
     "grade_id": "cell-88f11c2bbe9b3242",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.1.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cd2cc4ab3ec0c3f047a692762323a6e7",
     "grade": false,
     "grade_id": "cell-08411ec27d5e8325",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.1.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "In **Question 2.3.1** you performed 20 interim analyses of simulated data for an A/A design. Modify the code of **Question 2.3.5** to implement a Bonferroni correction as specified in **Question 3.1.0** in 100 experiments.\n",
    "\n",
    "Then compare the estimated type I error rate when a Bonferroni correction is used with the expected type I error rate value.\n",
    "\n",
    "*Assign your answer to an object called `answer3.1.2`. Your answer should be a tibble with two columns: `n_rejections_Bonf` and `expected_n_rejections`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e8d5080d61539d1f78ef41c4b9724456",
     "grade": false,
     "grade_id": "cell-c77e00f407e9b61d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer3.1.2 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "                            \n",
    "answer3.1.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "caf2a81dc6e505d7ff1b3b954dec6571",
     "grade": true,
     "grade_id": "cell-64cca985a6e4b549",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f3268d2c75236e7ec9893c5f099790d",
     "grade": false,
     "grade_id": "cell-bf09c89e531d91af",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### <font color=blue> Using a Bonferroni correction, the data can be sequentially analyzed and the experiment can be stopped earlier while controlling the type I error rate. </font>\n",
    "- For the simulated experiments in the example above, the type I error rate was 2%, which is now below the planned 5% value. \n",
    "\n",
    "As with other multiple comparison problems, the Bonferroni's correction in sequential analysis is very conservative and can affect the power of the test!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eecb23adf87228723e8e3428061e58c7",
     "grade": false,
     "grade_id": "cell-76077581b4638618",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2 Pocock boundaries\n",
    "\n",
    "As we recalled in **Question 3.1.1**, the Bonferroni correction can be implemented by adjusting the critical value to `qt(1 - 0.0025, 998) = 2.81`. \n",
    "\n",
    "However, Bonferroni's correction was originally designed for independent tests, which, by design is not true in this problem. \n",
    "\n",
    "> Sequential tests are nested so they are *not* independent. Thus, Bonferroni correction is not commonly used in A/B testing experiments\n",
    "\n",
    "Other methods have been proposed tailored for A/B testing. \n",
    "\n",
    "In this section we will examine the **Pocock method** to compute alternative critical values to evaluate interim analyses in sequential A/B testing.\n",
    "\n",
    "Similarly to Bonferroni's method, the **Pocock method** computes a *common* critical value for all interim analyses. However, the Pocock's boundary is not an adjustment of the quantile of a $t$-distribution.\n",
    "\n",
    "We can easily get the critical values for this design using `gsDesign::gsDesign()`.\n",
    "\n",
    "**Note 1**: `gsDesign()` outputs a full sequential design, not just the critical values to control a desired type I error!! Particularly important is the computation of the required sample size to achieve the designed power!! You can read more about this package [here](https://keaven.github.io/gsDesign/reference/gsDesign.html)\n",
    "\n",
    "**Note 2**: a caveat about this package is that two-sample tests are based on $z$-statistics, i.e., a case for which we assume that samples are drawn from Normal distributions with known SD. While this is usually an unrealistic assumption and in practice we use a $t$-test to compare means of two populations, results are nearly equivalent to a $z$-test. More can be read [here](https://keaven.github.io/gsDesign/articles/nNormal.html)  \n",
    "\n",
    "In the following exercises we will examine if the critical values of the Pocock design can be used to control the type I error rate. \n",
    "\n",
    "Let's start computing a Pocock design. Save the output in the object `design_pocock`. Extract the Pocock's critical values for each interim analyses and save them in an object called `crit_pocock`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "032f8cc3b265149ad557b9530f01d8fe",
     "grade": false,
     "grade_id": "cell-b20f739b98c5f734",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to get a Pocock design!\n",
    "\n",
    "design_pocock <- gsDesign(k = 20, #number of interim analysis planned\n",
    "                          test.type = 1, # for one-sided tests\n",
    "                          delta = 0, # default effect size\n",
    "                          alpha = 0.05, #type II error rate\n",
    "                          beta = 0.2, # type II error rate\n",
    "                          sfu = 'Pocock')\n",
    "                          \n",
    "crit_pocock <- design_pocock$upper$bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "535421ab8f06965ca9bb8bb5501db26c",
     "grade": false,
     "grade_id": "cell-c01bc9ca566a644a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "As we know, when performing a hypothesis test, we can either compare the $p$-value to a pre-specified significance level $\\alpha$ *or* we can compare the observered statistic to a critical value. \n",
    "\n",
    "Based on previous results, the Pocock method is more conservative than the Bonferroni correction. **True or False??**\n",
    "\n",
    "*Assign your answer to an object called answer3.2.0. Your answer should be either \"true\" or \"false\", surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a4f19fab05b7050c4fbb9e78b98ce8f",
     "grade": false,
     "grade_id": "cell-579d0fb205efe17f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer3.2.0 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32472b01c9b026efb9beda1a2a606ee3",
     "grade": true,
     "grade_id": "cell-f13cecff81f199a7",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.2.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1199930706ba9b3fc961aca8a1845b88",
     "grade": false,
     "grade_id": "cell-25450c2ce8317643",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "Using the data stored in `answer2.3.1`, plot the sequence of observed statistics for each interim analysis as a **line** with the incremental sample size on the $x$-axis and the value of the observed statistic on the $y$-axis. \n",
    "\n",
    "Add 3 dashed horizontal lines that indicate the following 3 boundaries (critical values): \n",
    "\n",
    "- a red line for the Pocock's critical values\n",
    "\n",
    "- a blue line for the Bonferroni's critical values\n",
    "\n",
    "- a black line for the unadjusted critical values\n",
    "\n",
    "The `ggplot()` object's name will be `sequential_stat`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2121afe6be0eb8c61c771abaee1d5435",
     "grade": false,
     "grade_id": "cell-5ef9722f4fe9480d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 15, repr.plot.height = 9) # Adjust these numbers so the plot looks good in your desktop.\n",
    "\n",
    "#crit_unadj <- qt(1 - ..., ...)\n",
    "#crit_bonferroni <- ...(1 - ..., ...)\n",
    "\n",
    "#sequential_stat <- \n",
    "#  answer2.3.1 %>%\n",
    "#  ggplot() +\n",
    "#  geom_line(aes(x = inc_sample_size, y = statistic)) +\n",
    "#  geom_point(aes(x = ..., y = ...)) +\n",
    "#  geom_hline(yintercept = ..., colour = \"red\", linetype = \"twodash\") +\n",
    "#  geom_point(aes(x = inc_sample_size, y = ...), colour = \"red\") +\n",
    "#  geom_text(x=850, y=crit_pocock + 0.15, size=6, label=\"Pocock\",colour = \"red\") +\n",
    "#  geom_hline(yintercept = ..., colour = \"blue\", linetype = \"twodash\") +\n",
    "#  geom_point(aes(x = inc_sample_size, y = rep(crit_Bonferroni, 20)), colour = \"blue\") +\n",
    "#  geom_text(x=850, y=crit_bonferroni + 0.15, size=6, label=\"Bonferroni\",colour = \"blue\") +\n",
    "#  geom_hline(yintercept = ..., linetype = \"twodash\") +\n",
    "#  geom_point(aes(x = inc_sample_size, y = rep(..., 20))) +\n",
    "#  geom_text(x=850, y=crit_unadj + 0.15, size=6, label=\"Unadjusted\") +\n",
    "#  theme(\n",
    "#    text = element_text(size = 18),\n",
    "#    plot.title = element_text(face = \"bold\"),\n",
    "#    axis.title = element_text(face = \"bold\")\n",
    "#  ) +\n",
    "#  ggtitle(\"Critical values in Sequential Designs\") +\n",
    "#  ylab(\"Statistic\") +\n",
    "#  xlab(\"Sample Size\") +\n",
    "#  coord_cartesian(ylim = c(-1, 3)) +\n",
    "#  scale_y_continuous(breaks = seq(-1, 3, by = 0.5))\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "sequential_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a25e01b46f6398ca54f44f025eadbf34",
     "grade": true,
     "grade_id": "cell-01e7452acb878966",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9de32381237be3dd520a3b7067b0fd2d",
     "grade": false,
     "grade_id": "cell-b2ca8eabb168eb3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "The compaign organizers have decided to monitor the data every 50 visitors per website and stop the experiment earlier if there's evidence of a difference between the group means. According to the data plotted **Question 3.2.1**, which of the following statement is correct?? \n",
    "\n",
    "**A.** The compaign organizers would never stop the experiment, regardless of the boundary used\n",
    "\n",
    "**B.** The compaign organizers would erroneously stop the experiment after the analysis of the second test, regardless of the boundary used\n",
    "\n",
    "**C.** The compaign organizers would erroneously stop the experiment after the analysis of the second test, only if they correct the critical values using a Bonferroni's method to control the type I error rate\n",
    "\n",
    "**D.** The compaign organizers would erroneously stop the experiment after the analysis of the second test if they use undadjusted $t$ critical values \n",
    "\n",
    "*Assign your answer to an object called `answer3.2.2`. Your answer should be one of `\"A\"`, `\"B\"`, or `\"C\"` surrounded by quotes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af1706741cd480bef6fd553c930fd93a",
     "grade": false,
     "grade_id": "cell-409ecf169b052d92",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer3.2.2 <- \n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d39979033bbffd1a6306537b5012c81c",
     "grade": true,
     "grade_id": "cell-2f1245af7c571bba",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.2.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b2c3ff4cd32d8af4bd749c93f666dbac",
     "grade": false,
     "grade_id": "cell-05dd6e2301bfa24c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 3.2.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "In **Question 2.3.1** you performed 20 interim analyses of simulated data for an A/A design. Modify the code of **Question 2.3.5** to implement a sequential analyses using Pocock's boundary to control the type I error in 100 experiments.\n",
    "\n",
    "Then compare the estimated type I error rate when the Pocock's method is used with the expected type I error rate value.\n",
    "\n",
    "*Assign your answer to an object called `answer3.2.3`. Your answer should be a tibble with two columns: `n_rejections_Pocock` and `expected_n_rejections`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "456f00e51d87a3f12ee8dcf0d8d4e12f",
     "grade": false,
     "grade_id": "cell-549d0aab861a20f3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#answer3.2.3 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "                            \n",
    "answer3.2.3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bf06d9e201420bf84ce7063ea8623db",
     "grade": true,
     "grade_id": "cell-ce2f87ff4dbcd7bc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_3.2.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "02e4dc6654b655fbaf139f258dfc63bf",
     "grade": false,
     "grade_id": "cell-c15252b8e2a0e330",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### <font color=blue> Using the Pocock's method, the data can be sequentially analyzed and the experiment can be stopped earlier while controlling the type I error rate. </font>\n",
    "- For the simulated experiments in the example above, the type I error rate was 7%, which close to the planned 5% value\n",
    "\n",
    "- As expected, this method is less conservative than the Bonferroni's correction\n",
    "\n",
    "In Tutorial 2, you will implement another sequential test method available in `gsDesign` package, called the **OâBrien-Fleming method**, which has conservative critical values for earlier interim analysis and less conservative values (closer to the unadjusted critical values) as more data are collected. In other words, bounds are not uniform. \n",
    "\n",
    "There are many other methods to implement principled peeking strategies in A/B testing. \n",
    "- A very popular and flexible method, implemented by [Optimizely](https://www.optimizely.com), computes a mixture sequential probability ratio test (mSPRT) tests and *always valid* $p$-values. The metholology and implementation are beyond the scope of this course but here's a nice [video](https://www.youtube.com/watch?v=AJX4W3MwKzU) that explains its key points without too many technical details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7728ecd089e163720956d0334f5c9e9",
     "grade": false,
     "grade_id": "cell-a3ee7bcb3608e036",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4. Summary and key concepts learned\n",
    "\n",
    "1. A/B testing refers to an experiment, in which users are randomly assigned to one of two variations of a product or service: control (A) and variation (B) to see if variation B should be used for improvement.\n",
    "\n",
    "\n",
    "2. The statistic used to test a hypothesis, the sample size calculation, the type I error rate specification and the desired power are all important and interconnected pieces of the experimental design! \n",
    "\n",
    "\n",
    "3. In classical hypothesis testing theory, the sample size must be fixed in advance when the experiment is designed!!\n",
    "\n",
    "\n",
    "4. Modern platforms allow the users to continuously monitor the p-values and confidence intervals of their tests as data are collected (peeking) in order to re-adjust their experiment dynamically. \n",
    "\n",
    "\n",
    "5. In particular, users would like to stop their experiments earlier depending on the results of interim analyses\n",
    "\n",
    "\n",
    "6. Naively stopping experiments earlier than planned will increase the probability of *incorrectly* rejecting the null hypothesis (i.e., when there is no real effect). Stops must be part of the experimental design and appropriate testing methods must be used!\n",
    "\n",
    "\n",
    "7. Sequential testing is just another flavour of a multiple comparison problem. If you make lots of comparisons, but donât correct for it, your error rates are inflated!! However, in sequential testing tests are nested and not independent.\n",
    "\n",
    "\n",
    "8. A possible way to control the type I error rated is to use a Bonferroni adjustment of the $p$-values (or equivalently the significance level or critical values). As with other multiple comparison problems, the Bonferroni's correction in sequential analysis is very conservative and can affect the power of the test!!\n",
    "\n",
    "\n",
    "9. The Pocock's method offers a less conservative way of controlling the type I error rate in sequential testing with early stops.\n",
    "\n",
    "\n",
    "10. *Principled* peeking is ok and even beneficial in A/B testing.\n",
    "\n",
    "> The experimental designt is a very important piece of any statistical analysis! "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,Rmd"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
