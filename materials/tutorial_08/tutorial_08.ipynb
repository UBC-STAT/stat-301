{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38172029",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1d160d3e14a917fb4e583ba8446e21dd",
     "grade": false,
     "grade_id": "cell-d29d09ae5b9ca86e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Tutorial 08 - Selection methods for generative and predictive models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da792029",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e88c9951634ac1d0d4a03e476c07362b",
     "grade": false,
     "grade_id": "cell-28a28a6ef881c6b4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "By the end of this section, students will be able to:\n",
    "\n",
    "- Give examples of questions that can be answered by generative models and others that can be answered by predictive models.\n",
    "- Discuss how the research question being asked impacts the statistical modelling procedures.\n",
    "- Explain how regularized methods, such as lasso and ridge, can be used to estimate a predictive or a generative model.\n",
    "- Distinguish the selection properties of lasso and ridge penalties.\n",
    "- Discuss why the model obtained directly from lasso is not the most suitable model for generative modelling and how post-lasso is one way to address this problem.\n",
    "- Write a computer script to perform lasso/ridge and use it to predict new outcomes.\n",
    "- Write a computer script to perform post-lasso and use it to estimate a generative model.\n",
    "- Discuss post-inference problems (e.g., double dipping into the data set) and current practical solutions available to address these (e.g., data-splitting techniques).\n",
    "- Write a computer script to apply currently available practical solutions to post inference problems.\n",
    "- Discuss how the research question being asked impacts the communication of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415e620",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fc97e46fc4944ece0072fccf8086402",
     "grade": false,
     "grade_id": "cell-7594064fa4282164",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading packages\n",
    "library(car)\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(broom)\n",
    "library(glmnet)\n",
    "library(leaps)\n",
    "library(faraway)\n",
    "library(mltools)\n",
    "source(\"tests_tutorial_08.R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54dfcd6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a85bfb41dfc4749dabd0d4bb12d5396b",
     "grade": false,
     "grade_id": "cell-58fcbe563a6a076f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Model Selection: Ridge\n",
    "\n",
    "We have learned that *shrinkage methods* can be used to build predictive models. Some of these methods can also be used to select variables. \n",
    "\n",
    "In particular, *Ridge method* will not select variables since the estimated coefficients won't be shrunk to zero. However, it can be used when\n",
    "\n",
    "- there are more predictors than observations\n",
    "  \n",
    "- to address multicollinearity (in fact, that was the primary goal)\n",
    "\n",
    "In this tutorial, you will use the dataset `fat` from the library `faraway` to build a Ridge regression and use it to predict the `brozek` value for men in a test set. \n",
    "\n",
    "**Recall**: This dataset contains the percentage of body fat and a whole variety of body measurements (continuous variables) of 252 men. You will use the variable `brozek` as the response variable and a subset 14 variables to build different models. Additional information about the data can be found in [Johnson (1996)](https://www.tandfonline.com/doi/full/10.1080/10691898.1996.11910505). \n",
    "\n",
    "Run the code below to create the working data frame called `fat_sample` and build the objects needed in next problems:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6882b2d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38cec0b7286293c3cab0b916a7d122bf",
     "grade": false,
     "grade_id": "cell-2a05a7dad6e0eaf6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The response variable `brozek` is the percent of body fat using Brozek's equation:\n",
    "\n",
    "$$\\texttt{brozek} = \\frac{457}{\\texttt{density}} - 414.2,$$\n",
    "\n",
    "where body `density` is measured in $\\text{g}/\\text{cm}^3$.\n",
    "\n",
    "The 14 input variables are:\n",
    "\n",
    "- `age`: Age in $\\text{years}$.\n",
    "- `weight`: Weight in $\\text{lb}$.\n",
    "- `height`: Height in $\\text{in}$.\n",
    "- `adipos`: Adiposity index in $\\text{kg}/\\text{m}^2$.\n",
    "\n",
    "$$\\texttt{adipos} = \\frac{\\texttt{weight}}{\\texttt{height}^2}$$\n",
    "\n",
    "- `neck`: Neck circumference in $\\text{cm}$.\n",
    "- `chest`: Chest circumference in $\\text{cm}$.\n",
    "- `abdom`: Abdomen circumference at the umbilicus and level with the iliac crest in $\\text{cm}$.\n",
    "- `hip`: Hip circumference in $\\text{cm}$.\n",
    "- `thigh`: Thigh circumference in $\\text{cm}$.\n",
    "- `knee`: Knee circumference in $\\text{cm}$.\n",
    "- `ankle`: Ankle circumference in $\\text{cm}$.\n",
    "- `biceps`: Extended biceps circumference in $\\text{cm}$.\n",
    "- `forearm`: Forearm circumference in $\\text{cm}$.\n",
    "- `wrist`: Wrist circumference distal to the styloid processes in $\\text{cm}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b619c747",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e903aa0e96e61f1a80af9dcc62ea2d21",
     "grade": false,
     "grade_id": "cell-786b8912ab7d504d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get a sample\n",
    "fat_sample <- fat %>%\n",
    "  select(\n",
    "    brozek, age, weight, height, adipos, neck, chest, abdom,\n",
    "    hip, thigh, knee, ankle, biceps, forearm, wrist\n",
    "  )\n",
    "\n",
    "# Split data into training and test sets\n",
    "set.seed(123)\n",
    "\n",
    "\n",
    "#Alternative code:\n",
    "training_fat  = fat_sample %>%\n",
    "  sample_frac(0.6)\n",
    "\n",
    "testing_fat = fat_sample %>%\n",
    "  setdiff(training_fat)\n",
    "\n",
    "\n",
    "# Build matrix and vector required by `glmnet`\n",
    "\n",
    "# Using `model.matrix()` to get the X matrix, the first column \n",
    "# corresponds to the intercept and needs to be deleted\n",
    "\n",
    "\n",
    "fat_X_train <- model.matrix(object = brozek ~ .,\n",
    "  data = training_fat)[, -1] \n",
    "fat_Y_train <- training_fat[, \"brozek\"]\n",
    "\n",
    "fat_X_test <- model.matrix(object = brozek ~ .,\n",
    "  data = testing_fat)[, -1]\n",
    "\n",
    "fat_Y_test <- testing_fat[, \"brozek\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698da9d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4e1b494529e414466dbf6c3396b90be8",
     "grade": false,
     "grade_id": "cell-b0f7341243c55d45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.0**\n",
    "<br>{points: 1}\n",
    "\n",
    "Now that we have our training data prepared in `fat_X_train` and `fat_Y_train`, we will select the value of $\\lambda$ that provides the smallest $\\text{MSE}_{\\text{test}}$ using cross-validation. \n",
    "\n",
    "We can do this automatically with function `cv.glmnet()` where `x` is the matrix of input variables and `y` is vector of training responses that we prepared. \n",
    "\n",
    "> **Heads up**: the method of Ridge regression is defined when `alpha = 0`. \n",
    "\n",
    "To select `lambda` we will use a **sequence** of values that goes from $\\lambda = \\exp(-5) = 0.0067$ to $\\lambda = \\exp(10) = 22026.5$. Internally, `glmnet` will use cross-validation to compare the test MSE at each of these values. Assign the function's output as `fat_cv_lambda_ridge`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c262bf4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2726fa05c01bab14d0b1b0bbe256f49",
     "grade": false,
     "grade_id": "cell-52febd5769a37a51",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(1234) # DO NOT CHANGE!\n",
    "\n",
    "# fat_cv_lambda_ridge <- ...(\n",
    "#   x = ..., y = ...,\n",
    "#   alpha = ...,\n",
    "#   lambda = exp(seq(-5, 10, 0.1))\n",
    "# )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a39a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cae0a307395ed3cb44527c6b2dbc5382",
     "grade": true,
     "grade_id": "cell-18a78ee10d2b9343",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e5f55",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ecb4d761eddfd3ec44b1847158fa81f",
     "grade": false,
     "grade_id": "cell-5876c55a6dec81c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.1**\n",
    "<br>{points: 1}\n",
    "\n",
    "We can visualize the estimated test MSE at each value of lambda in the sequence by using `fat_cv_lambda_ridge` and `plot()`. \n",
    "\n",
    "The resulting plot will indicate the $\\text{MSE}_{\\text{test}}$ on the $y$-axis (error bars show the variation of the test error in the different folds) along with the range of $\\lambda$ on the bottom $x$-axis on the natural log-scale. \n",
    "\n",
    "> **Heads up**: Ridge regression never shrinks estimators to zero, thus we see a value of `14` on the top $x$-axis. \n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a64166f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34574ad4f68c916279e79fa6622d480a",
     "grade": false,
     "grade_id": "cell-d97c2df4f4d42d2f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot_data <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "plot(plot_data, main = \"MSE of Ridge estimated by CV for different lambdas\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238ec80",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00609be3e0cb92acb9118c1b56bf4a9c",
     "grade": true,
     "grade_id": "cell-5f0cf0c7f5529806",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8160c487",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9107879864f4068aa781ddad12f968e1",
     "grade": false,
     "grade_id": "cell-68b60264988b73c1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.2**\n",
    "<br>{points: 1}\n",
    "\n",
    "The plot in **Question 1.1** also shows two vertical dotted lines. *Given an `object` coming from `cv.glmnet()`*, these lines correspond to two values of $\\lambda$:\n",
    "\n",
    "- $\\hat{\\lambda}_{\\text{min}}$ which minimizes MSE. It can be obtained with `object$lambda.min`.\n",
    "\n",
    "\n",
    "- $\\hat{\\lambda}_{\\text{1SE}}$ for which the MSE is within one standard error of the minimum. It can be obtained with `object$lambda.1se`.\n",
    "\n",
    "\n",
    "Using `fat_cv_lambda_ridge`, obtain the $\\hat{\\lambda}_{\\text{min}}$ and save it as `fat_lambda_min_MSE_ridge`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a876e4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8888ec65318f7a7b59273fc05cc4c716",
     "grade": false,
     "grade_id": "cell-f8302019baf0e946",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fat_lambda_min_MSE_ridge <- round(..., 4)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "fat_lambda_min_MSE_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed770e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c0933dea136985405ca770e2036e94e",
     "grade": true,
     "grade_id": "cell-aa84acea9f83e4f0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9652c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8b0fd90c8c399f5e98294dca57eb188",
     "grade": false,
     "grade_id": "cell-11cd98e7e77dda38",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.3**\n",
    "<br>{points: 1}\n",
    "\n",
    "Once we have selected a value of $\\lambda$, we can extract the estimated Ridge regression at that level of penalization. Store the estimated models in `fat_ridge_min_coef`.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8810da",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c06d4cf6c99da9da007c0dd1fdd22cd1",
     "grade": false,
     "grade_id": "cell-6247996ee6baff00",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(1234) # DO NOT CHANGE!\n",
    "\n",
    "# fat_ridge_min_coef <- ...(..., s = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "fat_ridge_min_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611adaad",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f72ba7bd170041fa45e631292c57d0b",
     "grade": true,
     "grade_id": "cell-403460fdc6dd4b11",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231731db",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b09e8879dbc2aaa39278930c2a3698e1",
     "grade": false,
     "grade_id": "cell-b9c46b4907252c05",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.4**\n",
    "<br>{points: 1}\n",
    "\n",
    "Let's compare the estimated regression coefficients of  `fat_ridge_min` with those of `fat_full_OLS`.\n",
    "\n",
    "Create a data frame called `fat_coef` with three columns:\n",
    "\n",
    "- `Full_OLS:` The estimated coefficients from `fat_full_OLS` obtained via function `coef()`.\n",
    "- `Ridge_min`: The estimated coefficients in `fat_ridge_min_coef`. Recall this is the estimated ridge regression with $\\hat{\\lambda}_{\\text{min}}$.\n",
    "    \n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56dfa57",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d697da3577c1fe743da5bb747edd8e9",
     "grade": false,
     "grade_id": "cell-41c97a5a038f5b37",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fat_full_OLS <- ...\n",
    "\n",
    "# fat_reg_coef <- cbind(\n",
    "#   Full_OLS = ...(...),\n",
    "#   Ridge_min = as.vector(...)) %>%\n",
    "#       round(4) %>% as.data.frame()\n",
    "\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "fat_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a3915",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "454fa657a4340269d651ef030b6eae78",
     "grade": true,
     "grade_id": "cell-e200ac42567e5c8c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.4()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e43c600",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca6373a38836ace7ab85822c616aafc8",
     "grade": false,
     "grade_id": "cell-7af1141952d12623",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.5**\n",
    "<br>{points: 1}\n",
    "\n",
    "Write code following the steps outlined below. \n",
    "\n",
    "- Using `predict()` and `fat_full_OLS`, obtain the (out-of-sample) predicted `brozek` values for men in `testing_fat`. Store them in a variable called `fat_test_pred_full_OLS`. \n",
    "\n",
    "Fill out those parts indicated with ..., uncomment the corresponding code in the cell below, and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732cc9d2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f051efe056168cc4dd82e1816071216e",
     "grade": false,
     "grade_id": "cell-2297ec6008034b96",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fat_test_pred_full_OLS <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(fat_test_pred_full_OLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7604f00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1f56fdff1769a96bfb9c4d1d77ca1a7",
     "grade": true,
     "grade_id": "cell-bc5e6cff16323212",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.5()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae7cb7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "096fe28ff87ea36184cd476d245ab5cf",
     "grade": false,
     "grade_id": "cell-8a6eaa6ba1bb3417",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.6**\n",
    "<br>{points: 1}\n",
    "\n",
    "We will now compute the **Mean Squared Error (MSE)** on the test set to evaluate the predictive model (the smaller the metric, the more better the model):\n",
    "\n",
    "> **Heads up:** a related measure commonly used is the **Root Mean Squared Error (RMSE) = $\\sqrt{\\text{MSE}}$**, which is the standard deviation of the prediction errors $y_i - \\hat{y}_i$. This metric has the same units as the response.\n",
    "\n",
    "Use the function `rmse()` from the `mltools` package to compute the $\\text{RMSE}_{\\text{test}}$ of the *predicted* brozed values in `fat_test_pred_full_OLS`.\n",
    "\n",
    "Store the computed RMSE metric in a tibble called `fat_RMSE_models` with two columns:\n",
    "\n",
    "- `Model`: The regression model from which we will obtain the prediction accuracy.\n",
    "- `RMSE`: The $\\text{RMSE}_{\\text{test}}$ corresponding to the model.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df9feb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d0a4b4e6093f921c81ff3fecc8c03a2",
     "grade": false,
     "grade_id": "cell-c6d9fa85904e6333",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fat_test_RMSEs <- tibble(\n",
    "#   Model = \"OLS Full Regression\",\n",
    "#   RMSE = ...(\n",
    "#     preds = ...,\n",
    "#     actuals = ...\n",
    "#   )\n",
    "# )\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "fat_test_RMSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c128b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "78ac622f2a6ddd6ec91be615f8af1a63",
     "grade": true,
     "grade_id": "cell-c33cd78592c228b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caac2e7d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "01072fd33c8293fd4d5228bd3c129e63",
     "grade": false,
     "grade_id": "cell-1b5aee0f9e18c5dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.7**\n",
    "<br>{points: 1}\n",
    "\n",
    "Use `fat_cv_lambda_ridge` and the level of penalization that minimizes the CV-MSE to predict the brozek index of men in the test set `testing_fat`, and call the resulting object `fat_test_pred_ridge_min`.\n",
    "\n",
    "> **Hint:** Use function `predict()` with the argument `newx` to specifiy the test set.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e4f36a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec6274ddb5f353967126729e87995070",
     "grade": false,
     "grade_id": "cell-06d8fba564348542",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fat_test_pred_ridge_min <- predict(...,\n",
    "#   newx = ..., ....)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640599f9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57cbe454dd7c0202689a5f9cc7867a50",
     "grade": true,
     "grade_id": "cell-b885be4545c4f590",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.7()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e93e0d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d30bf4fa32997f873a4a258668d0309",
     "grade": false,
     "grade_id": "cell-09136c4608cf6502",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.8**\n",
    "<br>{points: 1}\n",
    "\n",
    "Use the function `rmse()` to compute the $\\text{RMSE}_{\\text{test}}$ using the predicted values stored in `fat_test_pred_ridge_min`. \n",
    "\n",
    "Add this metric as an additional row in the tibble `fat_test_RMSEs`. Use `\"Ridge Regression with minimum MSE\"` in column `Model` and the corresponding values for $\\text{RMSE}_{\\text{test}}$ in column `RMSE`.\n",
    "\n",
    "**NOTE**: note that the code below binds rows into `fat_test_RMSEs`. Do not re-run this cell or restart the kernel if needed. Otherwise, this object will have extra (repeated) rows.\n",
    "\n",
    "*Fill out those parts indicated with `...`, uncomment the corresponding code in the cell below, and run it.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bac8628",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e861eb499fa79491f0b539618b53b023",
     "grade": false,
     "grade_id": "cell-6265b672edd860ec",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fat_test_RMSEs <- rbind(\n",
    "#   fat_test_RMSEs,\n",
    "#   tibble(\n",
    "#     Model = \"Ridge Regression with minimum MSE\",\n",
    "#     RMSE = ...(\n",
    "#        ...,\n",
    "#        ...\n",
    "#   )\n",
    "# )\n",
    "\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "fat_test_RMSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d08855",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "707b380dd7c25a84a7e0565d5ef2159a",
     "grade": true,
     "grade_id": "cell-2babb63d363b8d54",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_1.8()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967852d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f4eed1b999721f9286f59968579265e",
     "grade": false,
     "grade_id": "cell-fbaea8aa16ad36e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 1.9**\n",
    "<br>{points: 1}\n",
    "\n",
    "Based on your results in `fat_test_RMSEs`, which model shows the best prediction? Was this an expected result? Justify your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1d7bf4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90ec2febef502491061974d5039205e9",
     "grade": true,
     "grade_id": "cell-4ebd54748e26c8df",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "> *Your answer goes here.*\n",
    "\n",
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae7987",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6246223e2f7d6af20376d7ff08eff019",
     "grade": false,
     "grade_id": "cell-de4c5e5a0539af50",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Model Selection For Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461e9be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec9ddf355c96e9b5220a8b9734c369c5",
     "grade": false,
     "grade_id": "cell-71132aeff4463df4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the second part of this tutorial, you will select a generative model using a real data set and use it for inference. \n",
    "\n",
    "**Recall** the [Ames `Housing` dataset](https://www.kaggle.com/c/home-data-for-ml-course/) you worked on Worksheet 08. Let's refresh our memory: it was compiled by Dean De Cock, it has 79 input variables on different characteristics of residential houses in Ames, Iowa, USA that can be used to predict the property's final price, `SalePrice`. As in worksheet_08, we will focus our attention on 21 numerical input variables:\n",
    "\n",
    "- `LotFrontage`: Linear $\\text{ft}$ of street connected to the house.\n",
    "- `LotArea`: Lot size in $\\text{ft}^2$.\n",
    "- `MasVnrArea`: Masonry veneer area in $\\text{ft}^2$.\n",
    "- `TotalBsmtSF`: Total $\\text{ft}^2$ of basement area.\n",
    "- `GrLivArea`: Above grade (ground) living area in $\\text{ft}^2$.\n",
    "- `BsmtFullBath`: Number of full bathrooms in basement.\n",
    "- `BsmtHalfBath`: Number of half bathrooms in basement.\n",
    "- `FullBath`: Number of full bathrooms above grade.\n",
    "- `HalfBath`: Number of half bathroom above grade.\n",
    "- `BedroomAbvGr`: Number of bedrooms above grade (it does not include basement bedrooms).\n",
    "- `KitchenAbvGr`: Number of kitchens above grade.\n",
    "- `Fireplaces`: Number of fireplaces.\n",
    "- `GarageArea`: Garage's area in $\\text{ft}^2$.\n",
    "- `WoodDeckSF`: Wood deck area in $\\text{ft}^2$.\n",
    "- `OpenPorchSF`: Open porch area in $\\text{ft}^2$.\n",
    "- `EnclosedPorch`: Enclosed porch area in $\\text{ft}^2$.\n",
    "- `ScreenPorch`: Screen porch area in $\\text{ft}^2$.\n",
    "\n",
    "Let's start by loading the data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd63c17d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ae4f858b7ac4370744a0910a350253f",
     "grade": false,
     "grade_id": "cell-f650c86ecdf10f20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Load the housing data set\n",
    "housing_raw <- read_csv(\"data/Housing.csv\", col_types = cols())\n",
    "\n",
    "# Use `YearBuilt` and `YrSold` to create a variable `ageSold`\n",
    "housing_raw$ageSold <- housing_raw$YrSold - housing_raw$YearBuilt\n",
    "\n",
    "\n",
    "# Select subset of input variables\n",
    "housing_raw <- \n",
    "  housing_raw %>%\n",
    "  select(LotFrontage, LotArea, MasVnrArea, TotalBsmtSF, \n",
    "    GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, BedroomAbvGr, KitchenAbvGr, Fireplaces,\n",
    "    GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, ScreenPorch, PoolArea, ageSold, SalePrice\n",
    "  )\n",
    "\n",
    "# Remove those rows containing `NA`s and some outliers\n",
    "housing_raw <- \n",
    "    drop_na(housing_raw)  %>% \n",
    "    filter(LotArea < 20000)\n",
    "\n",
    "str(housing_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3278f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "41f7d6ebf0fe344c61f270f9fa8e4bb3",
     "grade": false,
     "grade_id": "cell-50321cb291721425",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Our objective in this tutorial is to obtain a model for inference. We want to study how the properties' values are affected by the different properties' attributes. We want to be able to:\n",
    "\n",
    "1. Interpret the parameters of the model;\n",
    "2. Identify relevant attributes (covariates); \n",
    "3. Have a measure of uncertainty of our estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f860668c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8a20b99af73118e4f2ef61167fae634b",
     "grade": false,
     "grade_id": "cell-e7da157741ea3009",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.0** \n",
    "<br> {points: 1}\n",
    "\n",
    "Since we do not know which variables are important/relevant, we will need to conduct a variable selection technique. Let's start by splitting the data set into two sets: (1) the first part, with 60% of the rows, will be used to select a model; and (2) the second part, will be for inference. \n",
    "\n",
    "> Note that the partition is similar to the training-test one used in prediction problems.\n",
    "\n",
    "Your job is to randomly select 60% of the rows and store them in an object called `housing_selection`. Store the remaining rows in an object called `housing_inference`.\n",
    "\n",
    "The `housing_inference` object is golden! It should not be touched before we select the variables. No peeking!!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d694f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1db63547fa861ec2d14558b3ec4079a0",
     "grade": false,
     "grade_id": "cell-985f13c4ad88cab4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(20211118) # Do not change this\n",
    "\n",
    "# Housing_split <- ...(..., prop = ..., strata = SalePrice)\n",
    "# housing_selection <- training(Housing_split)\n",
    "# housing_inference <- testing(Housing_split)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "head(housing_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37be3bd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8759a8ab826ab30874dd764e60824171",
     "grade": true,
     "grade_id": "cell-6054ca27cbfa32bf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.0()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f336079",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f06e776409fe1d473f5b28633f783199",
     "grade": false,
     "grade_id": "cell-11d4086e95021066",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.1** \n",
    "<br> {points: 1}\n",
    "\n",
    "As we discussed in the worksheet, there are many possible approaches for model selection. Let's focus on Lasso. Run Lasso on the `housing_selection` tibble and find the value `lambda` that provides the lowest Cross-validation MSE. (See `cv.glmnet` function.)\n",
    "\n",
    "_Save the result in an object named `lasso_model`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3237e5",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5fad7c5521bf0df7b0f9e42af1ab01d1",
     "grade": false,
     "grade_id": "cell-cb6bd457d0686565",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(20211118) # do not change this\n",
    "\n",
    "# lasso_model <-\n",
    "#     cv.glmnet(x = ... %>% ...(-...)%>% as.matrix(), \n",
    "#               y = ..., \n",
    "#               alpha = ...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "lasso_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec113d42",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6109926290a9a89498878b9d12261ae5",
     "grade": true,
     "grade_id": "cell-262df79caf0b3bd1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e358f7b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "60492b8b691b1087bb1e5689eab242a6",
     "grade": false,
     "grade_id": "cell-c1dda3a387b34864",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.2** \n",
    "<br> {points: 1}\n",
    "\n",
    "Write a code to extract the coefficients of the best lasso model found in the `lasso_model`. By best, we mean the one with the smallest MSE. \n",
    "\n",
    "_Save the result in an object named `beta_lasso`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51315e9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba9b441ce9dd7d85e33ca21147c20aba",
     "grade": false,
     "grade_id": "cell-acd2d3a8859a9cd2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(20211118) # do not change this\n",
    "\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "beta_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68763f5c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58120ba6504728868eae4fd1a1ec71e6",
     "grade": true,
     "grade_id": "cell-ee50b59df5cb0f4f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2cb07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aea7fa44edbb21e4525e200b906839ab",
     "grade": false,
     "grade_id": "cell-06e3152180dc9c5b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.3** \n",
    "<br> {points: 1}\n",
    "\n",
    "Extract the name of the covariates selected by Lasso in an object named `lasso_selected_covariates`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaa77b2",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab3d9119c4958587d4d6097feecf993f",
     "grade": false,
     "grade_id": "cell-14ead3643c9ab06d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lasso_selected_covariates <- as_tibble(\n",
    "        # as.matrix(...),\n",
    "        # rownames='covariate') %>%\n",
    "        # filter(covariate != '(Intercept)' & abs(s1) !=0) %>% \n",
    "        # pull(...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "lasso_selected_covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd94158",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d2b908d9d77c8da1206b269b0152eb70",
     "grade": true,
     "grade_id": "cell-c9cb0881a7edf8c8",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a7ab3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "df2b5b3067fa486c3e7888e9ac4cdeb5",
     "grade": false,
     "grade_id": "cell-61add4e6deeca1d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.4** \n",
    "<br> {points: 1}\n",
    "\n",
    "In **Question 1.4** of this tutorial you extracted the estimated coefficients obtained using Ridge. In **Question 2.3**, you identified the variables selected by LASSO. \n",
    "\n",
    "**What is a main difference between these two methods in terms of variable selection?** Comment on the numbers of variables selected in relation to the variables available in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc26b5c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bd9b587596702d522782a000d3fe366c",
     "grade": true,
     "grade_id": "cell-e208b12ca32db945",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "> *Your answer goes here.*\n",
    "\n",
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd7017",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "253469e8496df69c998eef9ac2726db3",
     "grade": false,
     "grade_id": "cell-b07c4fe7a2646768",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.5** \n",
    "<br> {points: 1}\n",
    "\n",
    "We expect that LASSO would remove highly correlated variables. However, LASSO can still fit a linear model on data sets with high levels of multicollinearity. Unfortunately, ordinary least squares cannot. To be on the safe side, let's check the variance inflator factor of the variables selected by LASSO. \n",
    "\n",
    "_Save the output in an object named `lasso_variables_vif`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad296477",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "70e9652de3968d9d1d3d0f56a7376920",
     "grade": false,
     "grade_id": "cell-afa71facbda57961",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lasso_variables_vif <- \n",
    "#    vif(...)\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "lasso_variables_vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a3a7e4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6dc8ae43abc55d27a65973c4cefc4146",
     "grade": true,
     "grade_id": "cell-b15f03793cb8f509",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.5()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ecb688",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "782370a54132981a8003ce1830f13936",
     "grade": false,
     "grade_id": "cell-7b7350b720570c76",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.6**\n",
    "<br>{points: 1}\n",
    "\n",
    "True or false?\n",
    "\n",
    "The `lasso_variables_vif` does not indicate a very concerning presence of multicollinearity. \n",
    "\n",
    "_Assign your answer to an object called `answer2.6`. Your answer should be either \"true\" or \"false\", surrounded by quotes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67f537",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c94059e25d10627b5b82524069f7f833",
     "grade": false,
     "grade_id": "cell-1bc8096b1175869d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# answer2.6 <- ...\n",
    "\n",
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d030219",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e293370a5d7eabb5bf2b14b936942106",
     "grade": true,
     "grade_id": "cell-147fee130248b744",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_2.6()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1211e88a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "749a26d6bfb671995f67ca065edc8713",
     "grade": false,
     "grade_id": "cell-017240641a0ef825",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.7** \n",
    "<br> {points: 1}\n",
    "\n",
    "Finally, let's use the covariates selected by lasso and stored in `lasso_selected_covariates` to fit a linear model using ordinary least squares.\n",
    "\n",
    "_Save the output in an object named `inference_model`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710469f7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "066168bb83535f1431aacd2fb32a08bb",
     "grade": false,
     "grade_id": "cell-9b0750c9fa46f4cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "fail() # No Answer - remove if you provide an answer\n",
    "\n",
    "summary(inference_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b58ee",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9ba6f14f7753ba3c45a710cdff48a49b",
     "grade": true,
     "grade_id": "cell-c5fb858fa1d1ca00",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_2.7()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dc29bf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06576607f29f1a04216e89ed0b20fffb",
     "grade": false,
     "grade_id": "cell-e45c0a6408e71e0b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question 2.8** \n",
    "<br> {points: 1}\n",
    "\n",
    "The model stored in `inference_model` has shown 5 non-significant variables at 5% significance level. Should we remove these variables and re-fit the model with them? Briefly explain why or why not. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4576c42c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e7bba6ccffa0dfcacd40a50c3714f43b",
     "grade": true,
     "grade_id": "cell-37a2865a0526fd39",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "> Your answer goes here\n",
    "\n",
    "DOUBLE CLICK TO EDIT **THIS CELL** AND REPLACE THIS TEXT WITH YOUR ANSWER."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
