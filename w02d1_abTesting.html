
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>A/B Testing &#8212; Statistical Modelling for Data Science</title>
    
  <link href="_static/css/theme.css" rel="stylesheet">
  <link href="_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Principled Peeking in A/B Testing" href="w02d2_abPeeking.html" />
    <link rel="prev" title="Statistical modelling for Data Science" href="intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Statistical Modelling for Data Science</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Statistical modelling for Data Science
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   A/B Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="w02d2_abPeeking.html">
   Principled Peeking in A/B Testing
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/w02d1_abTesting.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fw02d1_abTesting.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/w02d1_abTesting.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analysis-design">
   Analysis Design
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#case-study">
   Case study
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#obama-s-60-million-dollar-experiment">
     Obama’s 60 million dollar experiment
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#early-stopping">
   Early stopping
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-a-testing">
     A/A Testing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpretation">
     Interpretation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary-and-key-concepts-learned">
   Summary and key concepts learned
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>A/B Testing</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#overview">
   Overview
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analysis-design">
   Analysis Design
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#case-study">
   Case study
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#obama-s-60-million-dollar-experiment">
     Obama’s 60 million dollar experiment
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#early-stopping">
   Early stopping
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-a-testing">
     A/A Testing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interpretation">
     Interpretation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary-and-key-concepts-learned">
   Summary and key concepts learned
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="section" id="a-b-testing">
<h1>A/B Testing<a class="headerlink" href="#a-b-testing" title="Permalink to this headline">¶</a></h1>
<img src="https://github.com/UBC-STAT/stat-301/blob/master/supplementary-material/img/ABTesting.png?raw=true" width=700>
<p><em>Photos/Images by <a class="reference external" href="https://www.optimizely.com/insights/blog/how-obama-raised-60-million-by-running-a-simple-experiment/">Optimizely</a></em></p>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h2>
<p>This chapter provides an introduction to A/B testing and the early peeking problem. The goal is that you understand the main principles of A/B testing that will allow you to properly design, run, and analyze data from A/B tests. While you probably know the main concepts behind A/B testing, the usage of online platforms to collect, store and analyze data from A/B tests open new challenges. For example, people get tempted to peek at results before the A/B test ended and take actions usually result in false discoveries.</p>
<p>A/B Testing is a technique used to compare two variations of a product or service: control (A) and variation (B)</p>
<ul class="simple">
<li><p>A/B testing became very popular in the context of updating and improving websites.</p></li>
</ul>
<p>It’s main concepts are founded in the context of hypothesis testing and inference to compare population quantities from 2 distributions</p>
<ul class="simple">
<li><p>for example: comparison of two population means or population proportions</p></li>
</ul>
</div>
<div class="section" id="analysis-design">
<h2>Analysis Design<a class="headerlink" href="#analysis-design" title="Permalink to this headline">¶</a></h2>
<p>As in any other statistical anlaysis, important steps of an A/B testing experiment include,</p>
<ul class="simple">
<li><p>post the <em>question(s)</em> you want to answer using data</p></li>
<li><p><em>design</em> the experiment to address your question(s)</p></li>
<li><p>identify appropriate methodologies to analyze the data</p></li>
<li><p>run the experiment to collect data</p></li>
<li><p>analyze the data according to the experimental design and make decisions</p></li>
</ul>
</div>
<div class="section" id="case-study">
<h2>Case study<a class="headerlink" href="#case-study" title="Permalink to this headline">¶</a></h2>
<div class="section" id="obama-s-60-million-dollar-experiment">
<h3>Obama’s 60 million dollar experiment<a class="headerlink" href="#obama-s-60-million-dollar-experiment" title="Permalink to this headline">¶</a></h3>
<p>In 2008, Obama’s campaign was looking to increase the total amount of donations to the campaign. Organizers run an experiment to compare visitors’ responses to different versions of the website.</p>
<img src="https://github.com/UBC-STAT/stat-301/blob/master/supplementary-material/img/ABTesting.png?raw=true" width=700>
<p><em>A full description of this case study can be found <a class="reference external" href="https://www.optimizely.com/insights/blog/how-obama-raised-60-million-by-running-a-simple-experiment/">here</a>.</em></p>
<p>While there is not a unique way to design an A/B testing experiment, <em><strong>randomized controlled experiments</strong></em> are commonly used in practice. When participants are randomly assigned to the experimental group or the control group, you only expect to observe differences driven by the controlled effect (e.g., a new website) and not by other confounding factors.</p>
<p>Other decisions need to be made when designing an A/B testing experiment, including sample size, number of tests, methodology. Since the choices made would influence the results, companies usually run some calibration tests before running the actual experiment.</p>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p><strong>Question</strong>: Does visitors of the new website contribute with larger donations for the political campaign?</p>
<p><strong>Design</strong>: Randomly allocate 1000 visitors to each website (control and new)</p>
<p><strong>Method</strong>: Analyze the data sequentially in batches of 50 visitors per website. Use a classical <span class="math notranslate nohighlight">\(t\)</span>-test to run the analysis, compute <span class="math notranslate nohighlight">\(p\)</span>-values and confidence intervals</p>
<p><strong>Decision</strong>: Stop the experiment if the <span class="math notranslate nohighlight">\(p\)</span>-value of a test drops below a significance level of <span class="math notranslate nohighlight">\(0.05\)</span></p>
</div>
<p>So, what is new about A/B testing?</p>
</div>
</div>
<div class="section" id="early-stopping">
<h2>Early stopping<a class="headerlink" href="#early-stopping" title="Permalink to this headline">¶</a></h2>
<p>New platforms have been developed to assist companies to analyze, report and visualize the results of their experiments <strong>in real time</strong></p>
<img src="https://miro.medium.com/max/1400/1*W8mUB5A96ufsbMWLqScVOA.png" width=600>
<p><font color=grey>Figure by D. Meisner in Towards Data Science </font></p>
<p>These platforms allow the users to <em>continuously monitor</em> the <span class="math notranslate nohighlight">\(p\)</span>-values and confidence intervals in order to re-adjust their experiment dynamically.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>In classical hypothesis testing theory, the sample size must be fixed in advance when the experiment is designed!! Is it ok to peek at results before all the data are collected??</p>
</div>
<p>In general, there are large opportunity costs associated with longer experiments. Thus, users may prefer to adaptively determine the sample size of the experiments and make decisions before the planned experiment ends.</p>
<div class="tip admonition">
<p class="admonition-title">Definition</p>
<p><strong>Early stopping</strong> refers to ending the experiment earlier than originally designed.</p>
</div>
<p>Can we stop or re-design the experiment earlier if we have supporting evidence to do so?? Let’s answer this question using data!</p>
<div class="section" id="a-a-testing">
<h3>A/A Testing<a class="headerlink" href="#a-a-testing" title="Permalink to this headline">¶</a></h3>
<p>To examine the problem of early stopping, let’s simulate data for which <span class="math notranslate nohighlight">\(H_0\)</span> is true (i.e., there is no effect)</p>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p>All users are allocated to the same version of a website.</p>
</div>
<img src="https://github.com/UBC-STAT/stat-301/blob/master/supplementary-material/img/aa-Obama.png?raw=true" width=600>
<p>In such a scenario, data from both groups are generated from the same distribution. Thus, we know that rejecting <span class="math notranslate nohighlight">\(H_0\)</span>  is a mistake!</p>
<div class="admonition-simulation-example admonition">
<p class="admonition-title">Simulation Example</p>
<ul class="simple">
<li><p>generate 1000 data points per group (control and variation) from the same distribution (total sample size of 2000)</p></li>
<li><p>sequentially analyze the data in batches of 50 observations per group using a two-sample <span class="math notranslate nohighlight">\(t\)</span>-tests</p></li>
<li><p>sequentially compute and monitor the (raw) <span class="math notranslate nohighlight">\(p\)</span>-values</p></li>
<li><p>reject the null hypothesis if a <span class="math notranslate nohighlight">\(p\)</span>-value drops below <span class="math notranslate nohighlight">\(0.05\)</span> and stop the experiment.</p></li>
</ul>
</div>
<p>Simulating this kind of data and running the same analysis many times allows you examine the properties of the procedure used. For example, you can estimate the type I error rate by counting in how many experiments the <span class="math notranslate nohighlight">\(p\)</span>-value has dropped below the significance level and you erroneously reject the null hypothesis</p>
<div class="caution admonition">
<p class="admonition-title">Wrong Rejection</p>
<p>The data were generated from the same distribution (e.g., all users are allocated to the same version of a website). Thus, in principle, the <span class="math notranslate nohighlight">\(p\)</span>-value should not drop below 0.05. However, due to randomness, you may still find significant differences between the two groups. But how often does that occur??</p>
</div>
<p>Let’s start by simulating one such experiments and visualizing the results.</p>
<div class="cell tag_remove_output tag_remove_input docutils container">
</div>
<div class="cell tag_hide_input docutils container">
<div class="cell_input docutils container">
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># FUNCTION</span>
<span class="c1"># Two-sample t-test with tracking sequential statistic and p-values by incremental sample sizes until getting to n in each group.</span>

<span class="c1"># @param n (numeric): Initially planned sample size for each group (for simplicity, n needs to be a multiple of sample_increase_step).</span>
<span class="c1"># @param d_0 (numeric): effect size.</span>
<span class="c1"># @param mean_current (numeric): Population mean for control variation.</span>
<span class="c1"># @param sd_current (numeric): Population standard deviation for current variation.</span>
<span class="c1"># @param sd_new (numeric): Population standard deviation for new variation.</span>
<span class="c1"># @param sample_increase_step (numeric): Sample size increment.</span>

<span class="c1"># @return p.value.df: A tibble that has 3 columns:</span>
<span class="c1"># inc_sample_size, statistic, and p_value </span>

<span class="n">incremental_t_test</span> <span class="o">&lt;-</span> <span class="nf">function</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">d_0</span><span class="p">,</span> <span class="n">mean_current</span><span class="p">,</span> <span class="n">sd_current</span><span class="p">,</span> <span class="n">sd_new</span><span class="p">,</span> <span class="n">sample_increase_step</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">sample_current</span> <span class="o">&lt;-</span> <span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">mean</span> <span class="o">=</span> <span class="n">mean_current</span><span class="p">,</span> <span class="n">sd</span> <span class="o">=</span> <span class="n">sd_current</span><span class="p">)</span>
  <span class="n">sample_new</span> <span class="o">&lt;-</span> <span class="nf">rnorm</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">mean</span> <span class="o">=</span> <span class="n">mean_current</span> <span class="o">+</span> <span class="n">d_0</span><span class="p">,</span> <span class="n">sd</span> <span class="o">=</span> <span class="n">sd_new</span><span class="p">)</span>

  <span class="n">p.value.df</span> <span class="o">&lt;-</span> <span class="nf">tibble</span><span class="p">(</span>
    <span class="n">inc_sample_size</span> <span class="o">=</span> <span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">/</span> <span class="n">sample_increase_step</span><span class="p">),</span>
    <span class="n">statistic</span> <span class="o">=</span> <span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">/</span> <span class="n">sample_increase_step</span><span class="p">),</span>
    <span class="n">p_value</span> <span class="o">=</span> <span class="nf">rep</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="n">n</span> <span class="o">/</span> <span class="n">sample_increase_step</span><span class="p">)</span>
  <span class="p">)</span>

  <span class="n">current_sample_size</span> <span class="o">&lt;-</span> <span class="n">sample_increase_step</span>
  
  <span class="nf">for </span><span class="p">(</span><span class="n">i</span> <span class="n">in</span> <span class="m">1</span><span class="o">:</span><span class="nf">nrow</span><span class="p">(</span><span class="n">p.value.df</span><span class="p">))</span>
  <span class="p">{</span>
    <span class="n">t_test_results</span> <span class="o">&lt;-</span> <span class="nf">t.test</span><span class="p">(</span><span class="n">sample_new</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="n">current_sample_size</span><span class="p">],</span> <span class="n">sample_current</span><span class="p">[</span><span class="m">1</span><span class="o">:</span><span class="n">current_sample_size</span><span class="p">],</span>
      <span class="n">var.equal</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">,</span>
      <span class="n">alternative</span> <span class="o">=</span> <span class="s">&quot;greater&quot;</span>                      
    <span class="p">)</span>
    <span class="n">p.value.df</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s">&quot;statistic&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="nf">as_tibble</span><span class="p">(</span><span class="n">t_test_results</span><span class="o">$</span><span class="n">statistic</span><span class="p">)</span>
    <span class="n">p.value.df</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s">&quot;p_value&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="nf">as_tibble</span><span class="p">(</span><span class="n">t_test_results</span><span class="o">$</span><span class="n">p.value</span><span class="p">)</span>
    <span class="n">p.value.df</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s">&quot;inc_sample_size&quot;</span><span class="p">]</span> <span class="o">&lt;-</span> <span class="n">current_sample_size</span>
    <span class="n">current_sample_size</span> <span class="o">&lt;-</span> <span class="n">current_sample_size</span> <span class="o">+</span> <span class="n">sample_increase_step</span>
  <span class="p">}</span>

  <span class="nf">return</span><span class="p">(</span><span class="n">p.value.df</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1">#---------------------------------------------------------------</span>

<span class="c1">#TEST and PLOT</span>

<span class="nf">options</span><span class="p">(</span><span class="n">repr.plot.width</span> <span class="o">=</span> <span class="m">10</span><span class="p">,</span> <span class="n">repr.plot.height</span> <span class="o">=</span> <span class="m">5</span><span class="p">)</span> 
<span class="nf">options</span><span class="p">(</span><span class="n">warn</span><span class="o">=</span><span class="m">-1</span><span class="p">)</span>

<span class="nf">set.seed</span><span class="p">(</span><span class="m">301</span><span class="p">)</span>
<span class="n">answer2.1</span> <span class="o">&lt;-</span> 
    <span class="nf">incremental_t_test</span><span class="p">(</span><span class="n">n</span> <span class="o">=</span> <span class="m">1000</span><span class="p">,</span> <span class="n">d_0</span> <span class="o">=</span> <span class="m">0</span><span class="p">,</span> <span class="n">sample_increase_step</span> <span class="o">=</span> <span class="m">50</span><span class="p">,</span> <span class="n">mean_current</span> <span class="o">=</span> <span class="m">200</span><span class="p">,</span> <span class="n">sd_current</span> <span class="o">=</span> <span class="m">50</span><span class="p">,</span> <span class="n">sd_new</span> <span class="o">=</span> <span class="m">50</span><span class="p">)</span>

<span class="n">sequential_pvalue</span> <span class="o">&lt;-</span> 
  <span class="n">answer2.1</span> <span class="o">%&gt;%</span>
  <span class="nf">ggplot</span><span class="p">()</span> <span class="o">+</span>
  <span class="nf">geom_line</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">inc_sample_size</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">p_value</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">theme</span><span class="p">(</span>
    <span class="n">text</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">size</span> <span class="o">=</span> <span class="m">18</span><span class="p">),</span>
    <span class="n">plot.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">face</span> <span class="o">=</span> <span class="s">&quot;bold&quot;</span><span class="p">),</span>
    <span class="n">axis.title</span> <span class="o">=</span> <span class="nf">element_text</span><span class="p">(</span><span class="n">face</span> <span class="o">=</span> <span class="s">&quot;bold&quot;</span><span class="p">)</span>
  <span class="p">)</span> <span class="o">+</span> 
  <span class="nf">geom_point</span><span class="p">(</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">inc_sample_size</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">p_value</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">ggtitle</span><span class="p">(</span><span class="s">&quot;Evolution of p-values in Experiment 1&quot;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">ylab</span><span class="p">(</span><span class="s">&quot;p-value&quot;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">xlab</span><span class="p">(</span><span class="s">&quot;Sample Size&quot;</span><span class="p">)</span> <span class="o">+</span>
  <span class="nf">geom_hline</span><span class="p">(</span>
    <span class="n">yintercept</span> <span class="o">=</span> <span class="m">0.05</span><span class="p">,</span>
    <span class="n">colour</span> <span class="o">=</span> <span class="s">&quot;red&quot;</span><span class="p">,</span>
    <span class="n">linetype</span> <span class="o">=</span> <span class="s">&quot;twodash&quot;</span>
  <span class="p">)</span> <span class="o">+</span>
  <span class="nf">coord_cartesian</span><span class="p">(</span><span class="n">ylim</span> <span class="o">=</span> <span class="nf">c</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">1</span><span class="p">))</span> <span class="o">+</span>
  <span class="nf">scale_y_continuous</span><span class="p">(</span><span class="n">breaks</span> <span class="o">=</span> <span class="nf">seq</span><span class="p">(</span><span class="m">0</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="n">by</span> <span class="o">=</span> <span class="m">0.05</span><span class="p">))</span>

<span class="n">sequential_pvalue</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/w02d1_abTesting_10_0.png" src="_images/w02d1_abTesting_10_0.png" />
</div>
</div>
</div>
<div class="section" id="interpretation">
<h3>Interpretation<a class="headerlink" href="#interpretation" title="Permalink to this headline">¶</a></h3>
<p>After collecting data from 100 participants the <span class="math notranslate nohighlight">\(p\)</span>-value drops below <span class="math notranslate nohighlight">\(0.05\)</span> so the experiment is stopped. But we know that claiming a significance difference in this experiment is a mistake.</p>
<div class="admonition-example admonition">
<p class="admonition-title">Example</p>
<p>Changing the website is costly and may not really increase the size of the donations as expected</p>
</div>
<p>But, isn’t this mistake one potential result of the test?</p>
<div class="tip admonition">
<p class="admonition-title">Definition</p>
<p>In statistical hypothesis testing, rejecting <span class="math notranslate nohighlight">\(H_0\)</span> when it is true is known as the <strong>type I error</strong>. The probability of a type I error is equal to the significance level of the test.</p>
</div>
<p>In our example, the test was planned so that the probability to falsely rejecting <span class="math notranslate nohighlight">\(H_0\)</span> is 5%. So, why is this a problem??</p>
<div class="caution admonition">
<p class="admonition-title">Type I error rate inflation</p>
<p>The problem is that the probability of falsely rejecting <span class="math notranslate nohighlight">\(H_0\)</span> may be larger than expected!</p>
</div>
<p>To know if the probability of falsely rejecting <span class="math notranslate nohighlight">\(H_0\)</span> is larger than 5%, we need to run <em>many</em> of these experiments!!</p>
<p>The figure below shows the p-value trajectory of 100 experiments. We see that the p-values of more than 5% of the experiments are below the significance level.</p>
<center>
<img src="https://github.com/UBC-STAT/stat-301/blob/master/supplementary-material/img/aa-Obama-pval100.png?raw=true" width=900>
</center>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>It can be proved, mathematically, that under the null hypothesis, the classical <span class="math notranslate nohighlight">\(p\)</span>-value will <em>always</em> cross <span class="math notranslate nohighlight">\(\alpha\)</span> if the experimenter waits long enough<span class="math notranslate nohighlight">\(^{*}\)</span>. This means that with increasing data, the probability of falsely rejecting a true <span class="math notranslate nohighlight">\(H_0\)</span> approaches to 1!</p>
</div>
<p>[*] David Siegmund. 1985. Sequential analysis: tests and confidence intervals.
Springer.</p>
</div>
</div>
<div class="section" id="summary-and-key-concepts-learned">
<h2>Summary and key concepts learned<a class="headerlink" href="#summary-and-key-concepts-learned" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>A/B testing refers to an experiment, in which users are randomly assigned to one of two variations of a product or service: control (A) and variation (B) to see if variation B should be used for improvement.</p></li>
<li><p>The statistic used to test a hypothesis, the sample size calculation, the type I error rate specification and the desired power are all important and interconnected pieces of the experimental design!</p></li>
<li><p>In classical hypothesis testing theory, the sample size must be fixed in advance when the experiment is designed!!</p></li>
<li><p>Modern platforms allow the users to continuously monitor the p-values and confidence intervals of their tests as data are collected (peeking) in order to re-adjust their experiment dynamically.</p></li>
<li><p>Stopping an experiment and rejecting <span class="math notranslate nohighlight">\(H_0\)</span> as soon as the <span class="math notranslate nohighlight">\(p\)</span>-value is below the specified significance level can drastically inflate the type I error rate</p></li>
</ol>
<div class="admonition attention">
<p class="admonition-title">Attention</p>
<p>Controlling the risk of wrongly rejecting the null hypothesis is not an easy task in A/B testing if peeking and early stops are allowed!</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "r"
        },
        kernelOptions: {
            kernelName: "ir",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ir'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="intro.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Statistical modelling for Data Science</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="w02d2_abPeeking.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Principled Peeking in A/B Testing</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Gabriela Cohen Freue<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>